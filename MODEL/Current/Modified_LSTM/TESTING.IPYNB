{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9425a5",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c36a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c73c8",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ab9a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEQUENCE_LENGTH = 48\n",
    "APPEND_FLAGS = True\n",
    "SELECT_JOINTS = [0, 4, 8, 12, 16, 20]\n",
    "DERIVED_PER_JOINT = 5\n",
    "DERIVED_DIM = len(SELECT_JOINTS) * 2 * DERIVED_PER_JOINT\n",
    "BASE_HAND_DIM = 42 * 3\n",
    "FEATURE_DIM = BASE_HAND_DIM + DERIVED_DIM + (2 if APPEND_FLAGS else 0)\n",
    "FLAG_START = FEATURE_DIM - 2\n",
    "FLAG_END = FEATURE_DIM\n",
    "FRAME_STRIDE = 2\n",
    "MAX_CARRY_FRAMES = 3\n",
    "MIN_PALM_SCALE = 0.02\n",
    "CLIP_COORD = 5.0\n",
    "INVERT_HANDEDNESS = True  \n",
    "\n",
    "# Face and Pose Anchors\n",
    "FACE_IDXS = {\n",
    "    \"nose\": 1,\n",
    "    \"forehead\": 10,\n",
    "    \"lip_u\": 13,\n",
    "    \"brow_r\": 65,\n",
    "    \"brow_l\": 295,\n",
    "    \"chin\": 152\n",
    "}\n",
    "POSE_IDXS = {\"L_SH\": 11, \"R_SH\": 12}\n",
    "\n",
    "def get_detector():\n",
    "    return mp.solutions.holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        smooth_landmarks=True,\n",
    "        refine_face_landmarks=False,   \n",
    "        min_detection_confidence=0.55,\n",
    "        min_tracking_confidence=0.55,\n",
    "        enable_segmentation=False\n",
    "    )\n",
    "\n",
    "def get_lr_pts(res):\n",
    "    if res is None:\n",
    "        return None, None\n",
    "    L = (np.array([[lm.x, lm.y, lm.z] for lm in res.left_hand_landmarks.landmark], np.float32)\n",
    "         if getattr(res, \"left_hand_landmarks\", None) else None)\n",
    "    R = (np.array([[lm.x, lm.y, lm.z] for lm in res.right_hand_landmarks.landmark], np.float32)\n",
    "         if getattr(res, \"right_hand_landmarks\", None) else None)\n",
    "    if INVERT_HANDEDNESS:\n",
    "        L, R = R, L\n",
    "    return L, R\n",
    "\n",
    "def get_anchors(res):\n",
    "    if res is None:\n",
    "        return None\n",
    "    anchors = {}\n",
    "\n",
    "    # Pose (shoulders)\n",
    "    if getattr(res, \"pose_landmarks\", None):\n",
    "        lm = res.pose_landmarks.landmark\n",
    "        anchors[\"L_SH\"] = np.array([lm[POSE_IDXS[\"L_SH\"]].x, lm[POSE_IDXS[\"L_SH\"]].y, lm[POSE_IDXS[\"L_SH\"]].z], np.float32)\n",
    "        anchors[\"R_SH\"] = np.array([lm[POSE_IDXS[\"R_SH\"]].x, lm[POSE_IDXS[\"R_SH\"]].y, lm[POSE_IDXS[\"R_SH\"]].z], np.float32)\n",
    "    else:\n",
    "        # global norm will fall back to per-hand normalization\n",
    "        pass\n",
    "\n",
    "    # Face (used for altitude features)\n",
    "    if getattr(res, \"face_landmarks\", None):\n",
    "        lm = res.face_landmarks.landmark\n",
    "        for key, idx in FACE_IDXS.items():\n",
    "            anchors[key] = np.array([lm[idx].x, lm[idx].y, lm[idx].z], np.float32)\n",
    "\n",
    "    return anchors if anchors else None\n",
    "\n",
    "def normalize_hand(pts: np.ndarray) -> np.ndarray: # Normalize hand relative to wrist–middle distance.\n",
    "    if pts is None or pts.shape != (21, 3):\n",
    "        return np.zeros((21, 3), np.float32)\n",
    "    wrist, mid = pts[0], pts[9]\n",
    "    scale = float(np.linalg.norm(mid[:2] - wrist[:2]))\n",
    "    if not np.isfinite(scale) or scale < MIN_PALM_SCALE:\n",
    "        scale = MIN_PALM_SCALE\n",
    "    out = (pts - wrist) / scale\n",
    "    return np.clip(out, -CLIP_COORD, CLIP_COORD).astype(np.float32)\n",
    "\n",
    "def normalize_global(L_pts, R_pts, anchors): # Normalize hands by shoulder distance\n",
    "    if not anchors or (\"L_SH\" not in anchors) or (\"R_SH\" not in anchors):\n",
    "        return normalize_hand(L_pts), normalize_hand(R_pts)\n",
    "\n",
    "    C = (anchors[\"L_SH\"] + anchors[\"R_SH\"]) / 2.0\n",
    "    scale = np.linalg.norm((anchors[\"L_SH\"] - anchors[\"R_SH\"])[:2])\n",
    "    if not np.isfinite(scale) or scale < 1e-6:\n",
    "        scale = 1e-6\n",
    "\n",
    "    def _norm(pts):\n",
    "        if pts is None or pts.shape != (21, 3):\n",
    "            return np.zeros((21, 3), np.float32)\n",
    "        out = (pts - C) / scale\n",
    "        return np.clip(out, -CLIP_COORD, CLIP_COORD).astype(np.float32)\n",
    "\n",
    "    return _norm(L_pts), _norm(R_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54da99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] 33 gesture classes detected:\n",
      "  • Color_Black\n",
      "  • Color_Blue\n",
      "  • Color_Brown\n",
      "  • Color_Dark\n",
      "  • Color_Gray\n",
      "  • Color_Green\n",
      "  • Color_Light\n",
      "  • Color_Orange\n",
      "  • Color_Pink\n",
      "  • Color_Red\n",
      "  • Color_Violet\n",
      "  • Color_White\n",
      "  • Color_Yellow\n",
      "  • Family_Auntie\n",
      "  • Family_Cousin\n",
      "  • Family_Daughter\n",
      "  • Family_Father\n",
      "  • Family_Grandfather\n",
      "  • Family_Grandmother\n",
      "  • Family_Mother\n",
      "  • Family_Parents\n",
      "  • Family_Son\n",
      "  • Family_Uncle\n",
      "  • Numbers_Eight\n",
      "  • Numbers_Five\n",
      "  • Numbers_Four\n",
      "  • Numbers_Nine\n",
      "  • Numbers_One\n",
      "  • Numbers_Seven\n",
      "  • Numbers_Six\n",
      "  • Numbers_Ten\n",
      "  • Numbers_Three\n",
      "  • Numbers_Two\n",
      "\n",
      "[OK] Feature dimension: 188 (126 coords + 60 altitude + 2 flags)\n"
     ]
    }
   ],
   "source": [
    "# Altitude Features\n",
    "def derived_altitude_features(L, R, anchors):\n",
    "    out = []\n",
    "    if anchors is None:\n",
    "        return np.zeros((DERIVED_DIM,), np.float32)\n",
    "\n",
    "    req = [\"nose\", \"chin\", \"forehead\", \"lip_u\", \"brow_r\", \"brow_l\"]\n",
    "    if not all(k in anchors for k in req):\n",
    "        return np.zeros((DERIVED_DIM,), np.float32)\n",
    "\n",
    "    brow_y = 0.5 * (anchors[\"brow_r\"][1] + anchors[\"brow_l\"][1])\n",
    "\n",
    "    for H in (L, R):\n",
    "        H = np.zeros((21, 3), np.float32) if H is None else H\n",
    "        for j in SELECT_JOINTS:\n",
    "            p = H[j]\n",
    "            out.extend([\n",
    "                p[1] - anchors[\"chin\"][1],\n",
    "                p[1] - anchors[\"lip_u\"][1],\n",
    "                p[1] - brow_y,\n",
    "                p[1] - anchors[\"forehead\"][1],\n",
    "                p[2] - anchors[\"nose\"][2],\n",
    "            ])\n",
    "    return np.asarray(out, np.float32)\n",
    "\n",
    "def pack_feature_with_anchors(L_pts, R_pts, lf, rf, anchors):\n",
    "    Lg, Rg = normalize_global(L_pts, R_pts, anchors)\n",
    "    feat = np.concatenate([Lg.reshape(-1), Rg.reshape(-1)], axis=0)\n",
    "    d = derived_altitude_features(Lg, Rg, anchors)\n",
    "    feat = np.concatenate([feat, d], axis=0)\n",
    "    if APPEND_FLAGS:\n",
    "        feat = np.concatenate([feat, np.array([lf, rf], np.float32)], axis=0)\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "# Auto detect signs from classes\n",
    "DATASET_DIR = Path(r\"C:\\Users\\Jerome\\Project Design\\KEYPOINTS\")\n",
    "CLASSES = sorted([d.name for d in DATASET_DIR.iterdir() if d.is_dir()])\n",
    "print(f\"[INIT] {len(CLASSES)} gesture classes detected:\")\n",
    "for c in CLASSES:\n",
    "    print(\"  •\", c)\n",
    "\n",
    "print(f\"\\n[OK] Feature dimension: {FEATURE_DIM} (126 coords + 60 altitude + 2 flags)\")\n",
    "\n",
    "def split_coords_derived_flags(seq: np.ndarray):\n",
    "    T, D = seq.shape\n",
    "    coords  = seq[:, :BASE_HAND_DIM].reshape(T, 42, 3).astype(np.float32)\n",
    "    derived = np.zeros((T, DERIVED_DIM), np.float32)\n",
    "    flags   = np.zeros((T, 2), np.float32)\n",
    "    if D >= (BASE_HAND_DIM + DERIVED_DIM + (2 if APPEND_FLAGS else 0)):\n",
    "        derived = seq[:, BASE_HAND_DIM:BASE_HAND_DIM+DERIVED_DIM].astype(np.float32)\n",
    "        if APPEND_FLAGS:\n",
    "            flags = seq[:, -2:].astype(np.float32)\n",
    "    elif APPEND_FLAGS and D >= (BASE_HAND_DIM + 2):\n",
    "        flags = seq[:, -2:].astype(np.float32)\n",
    "    return coords, derived, flags\n",
    "\n",
    "def combine_coords_derived_flags(coords: np.ndarray, derived: np.ndarray, flags: np.ndarray):\n",
    "    T = coords.shape[0]\n",
    "    out = coords.reshape(T, BASE_HAND_DIM).astype(np.float32)\n",
    "    out = np.concatenate([out, derived.astype(np.float32)], axis=1)\n",
    "    if APPEND_FLAGS:\n",
    "        out = np.concatenate([out, flags.astype(np.float32)], axis=1)\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "def resample_to_length(coords: np.ndarray, flags: np.ndarray, target_len: int):\n",
    "    T = coords.shape[0]\n",
    "    if T == target_len:\n",
    "        return coords.astype(np.float32), flags.astype(np.float32)\n",
    "    idx = np.linspace(0, T - 1, num=target_len)\n",
    "    lo = np.floor(idx).astype(int)\n",
    "    hi = np.clip(lo + 1, 0, T - 1)\n",
    "    w  = (idx - lo)[:, None, None]\n",
    "    coords_out = (1 - w) * coords[lo] + w * coords[hi]\n",
    "    flags_out  = flags[np.round(idx).astype(int)]\n",
    "    return coords_out.astype(np.float32), flags_out.astype(np.float32)\n",
    "\n",
    "def resample_to_length_vec(X: np.ndarray, target_len: int):\n",
    "    T = X.shape[0]\n",
    "    if T == target_len:\n",
    "        return X.astype(np.float32)\n",
    "    idx = np.linspace(0, T - 1, num=target_len)\n",
    "    lo = np.floor(idx).astype(int)\n",
    "    hi = np.clip(lo + 1, 0, T - 1)\n",
    "    w  = (idx - lo)[:, None]\n",
    "    X_out = (1 - w) * X[lo] + w[...]* X[hi]\n",
    "    return X_out.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afb879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_fix(seq: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    PAD_HEAD, PAD_TAIL = 5, 5\n",
    "    coords, derived, flags = split_coords_derived_flags(seq)\n",
    "    T = coords.shape[0]\n",
    "    if T == 0:\n",
    "        return seq.astype(np.float32)\n",
    "\n",
    "    # activity = 0.7 motion + 0.3 detection\n",
    "    v = np.diff(coords, axis=0)\n",
    "    motion = np.linalg.norm(v, axis=(1,2))\n",
    "    motion = np.r_[motion[:1], motion]\n",
    "    det = (flags.sum(axis=1) > 0.5).astype(np.float32)\n",
    "\n",
    "    def _norm01(x, eps=1e-8):\n",
    "        if x.size == 0: return x\n",
    "        lo, hi = float(x.min()), float(x.max())\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or (hi - lo) < eps:\n",
    "            return np.zeros_like(x, dtype=np.float32)\n",
    "        return ((x - lo) / (hi - lo)).astype(np.float32)\n",
    "\n",
    "    m_norm = _norm01(motion)\n",
    "    score = 0.7*m_norm + 0.3*det\n",
    "\n",
    "    CORE_LEN = max(8, target_len - (PAD_HEAD + PAD_TAIL))\n",
    "\n",
    "    def _sliding_best_window(s, win):\n",
    "        win = max(1, min(win, len(s)))\n",
    "        c = np.r_[0.0, np.cumsum(s, dtype=np.float64)]\n",
    "        sums = c[win:] - c[:-win]\n",
    "        j = int(np.argmax(sums))\n",
    "        return j, j + win\n",
    "\n",
    "    start, end = _sliding_best_window(score, min(CORE_LEN, T))\n",
    "    win_coords  = coords[start:end]\n",
    "    win_derived = derived[start:end]\n",
    "    win_flags   = flags[start:end]\n",
    "\n",
    "    # local onset alignment\n",
    "    if win_coords.shape[0] >= 2:\n",
    "        v_loc   = np.diff(win_coords, axis=0)\n",
    "        mot_loc = np.linalg.norm(v_loc, axis=(1,2))\n",
    "        mot_loc = np.r_[mot_loc[:1], mot_loc]\n",
    "        m_loc   = _norm01(mot_loc)\n",
    "        det_loc = (win_flags.sum(axis=1) > 0.5).astype(np.float32)\n",
    "\n",
    "        eps_onset, k = 0.08, 2\n",
    "        active = (m_loc > eps_onset) & (det_loc > 0.5)\n",
    "        onset_idx, run = 0, 0\n",
    "        for i, a in enumerate(active):\n",
    "            run = run + 1 if a else 0\n",
    "            if run >= k:\n",
    "                onset_idx = i - k + 1\n",
    "                break\n",
    "        if 0 < onset_idx < win_coords.shape[0]-1:\n",
    "            win_coords  = win_coords[onset_idx:]\n",
    "            win_derived = win_derived[onset_idx:]\n",
    "            win_flags   = win_flags[onset_idx:]\n",
    "\n",
    "    # resample core\n",
    "    core_coords, core_flags = resample_to_length(win_coords, win_flags, CORE_LEN)\n",
    "    core_derived = resample_to_length_vec(win_derived, CORE_LEN)\n",
    "\n",
    "    # head zeros\n",
    "    head_coords  = np.zeros((PAD_HEAD, 42, 3),       np.float32)\n",
    "    head_derived = np.zeros((PAD_HEAD, DERIVED_DIM), np.float32)\n",
    "    head_flags   = np.zeros((PAD_HEAD, 2),           np.float32)\n",
    "\n",
    "    # tail fade to zero, flags zero\n",
    "    if PAD_TAIL > 0:\n",
    "        last_c = core_coords[-1:].copy()\n",
    "        last_d = core_derived[-1:].copy()\n",
    "        alphas = np.linspace(1.0 - 1.0/max(1,PAD_TAIL), 0.0, num=PAD_TAIL, dtype=np.float32)\n",
    "        tail_coords  = np.repeat(last_c, PAD_TAIL, axis=0) * alphas[:, None, None]\n",
    "        tail_derived = np.repeat(last_d, PAD_TAIL, axis=0) * alphas[:, None]\n",
    "        tail_flags   = np.zeros((PAD_TAIL, 2), np.float32)\n",
    "    else:\n",
    "        tail_coords  = np.empty((0,42,3), np.float32)\n",
    "        tail_derived = np.empty((0,DERIVED_DIM), np.float32)\n",
    "        tail_flags   = np.empty((0,2), np.float32)\n",
    "\n",
    "    out_coords  = np.concatenate([head_coords,  core_coords,  tail_coords],  axis=0)\n",
    "    out_derived = np.concatenate([head_derived, core_derived, tail_derived], axis=0)\n",
    "    out_flags   = np.concatenate([head_flags,   core_flags,   tail_flags],   axis=0)\n",
    "\n",
    "    # exact len guard\n",
    "    if out_coords.shape[0] != target_len:\n",
    "        need = target_len - out_coords.shape[0]\n",
    "        if need > 0:\n",
    "            zc = np.zeros((need, 42, 3),       np.float32)\n",
    "            zd = np.zeros((need, DERIVED_DIM), np.float32)\n",
    "            zf = np.zeros((need, 2),           np.float32)\n",
    "            out_coords  = np.concatenate([out_coords,  zc], axis=0)\n",
    "            out_derived = np.concatenate([out_derived, zd], axis=0)\n",
    "            out_flags   = np.concatenate([out_flags,   zf], axis=0)\n",
    "        else:\n",
    "            out_coords  = out_coords[:target_len]\n",
    "            out_derived = out_derived[:target_len]\n",
    "            out_flags   = out_flags[:target_len]\n",
    "\n",
    "    return combine_coords_derived_flags(out_coords, out_derived, out_flags).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6863f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded: run24.pt\n",
      "Parameters: 992,545\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ModifiedLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes,\n",
    "                 dropout=0.45, use_layernorm=True):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_layers = torch.nn.ModuleList([\n",
    "            torch.nn.LSTM(input_size if i == 0 else hidden_size,\n",
    "                          hidden_size, batch_first=True)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.layernorms = torch.nn.ModuleList(\n",
    "            [torch.nn.LayerNorm(hidden_size) for _ in range(num_layers)]\n",
    "        ) if use_layernorm else None\n",
    "        self.act = torch.nn.ReLU(inplace=True)\n",
    "        self.drop = torch.nn.Dropout(dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, reset_mask=None):\n",
    "        for i, lstm in enumerate(self.lstm_layers):\n",
    "            x, _ = lstm(x)\n",
    "            if self.layernorms:\n",
    "                x = self.layernorms[i](x)\n",
    "            x = self.act(x)\n",
    "            x = self.drop(x)\n",
    "            if reset_mask is not None:\n",
    "                x = x * reset_mask.unsqueeze(-1)\n",
    "        return self.fc(x.mean(dim=1))\n",
    "\n",
    "ckpt_path = Path(r\"C:\\Users\\Jerome\\Project Design\\ModifiedLSTM_best\\run24.pt\")  # or latest runN.pt\n",
    "raw_state = torch.load(str(ckpt_path), map_location=device)\n",
    "state_dict = raw_state[\"model_state_dict\"] if \"model_state_dict\" in raw_state else raw_state\n",
    "\n",
    "model = ModifiedLSTM(FEATURE_DIM, 256, 2, len(CLASSES), dropout=0.35).to(device).eval()  # HS=256, NL=2\n",
    "model.load_state_dict(state_dict)\n",
    "print(f\"[OK] Loaded: {ckpt_path.name}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c0d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Helper functions ready (thr/EMA tuned)\n"
     ]
    }
   ],
   "source": [
    "BASE_THRESH = 0.60   # relaxed a bit\n",
    "EMA_ALPHA   = 0.40   # smoother\n",
    "N_CONSEC    = 4      # more stable\n",
    "SHOW_FPS    = True\n",
    "CARRY_NOISE = 0.001\n",
    "SHOW_VIS    = False\n",
    "\n",
    "try:\n",
    "    import winsound\n",
    "    def _beep(freq=800, dur=120):\n",
    "        try: winsound.Beep(freq, dur)\n",
    "        except: pass\n",
    "except Exception:\n",
    "    def _beep(freq=800, dur=120): \n",
    "        pass\n",
    "\n",
    "def softmax_np(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def get_threshold(class_idx):\n",
    "    return BASE_THRESH\n",
    "\n",
    "def parse_class_name(class_name):\n",
    "    parts = class_name.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        category = parts[0]\n",
    "        value = '_'.join(parts[1:])\n",
    "        return {'category': category, 'value': value, 'full': class_name}\n",
    "    return {'category': class_name, 'value': class_name, 'full': class_name}\n",
    "\n",
    "def get_all_categories():\n",
    "    categories = set()\n",
    "    for cls in CLASSES:\n",
    "        parsed = parse_class_name(cls)\n",
    "        categories.add(parsed['category'])\n",
    "    return sorted(list(categories))\n",
    "\n",
    "def get_values_in_category(category):\n",
    "    values = []\n",
    "    for cls in CLASSES:\n",
    "        parsed = parse_class_name(cls)\n",
    "        if parsed['category'] == category:\n",
    "            values.append(parsed['value'])\n",
    "    return sorted(list(set(values)))\n",
    "\n",
    "def get_class_index(category, value):\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        parsed = parse_class_name(cls)\n",
    "        if parsed['category'] == category and parsed['value'] == value:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def draw_center_text(img, text, y, scale=1.0, color=(230,230,230), thick=2):\n",
    "    W = img.shape[1]\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, scale, thick)\n",
    "    x = (W - tw) // 2\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, color, thick, cv2.LINE_AA)\n",
    "\n",
    "def draw_progress_bar(img, x0, y0, w, h, p, fg=(90,200,255), bg=(40,40,40)):\n",
    "    p = max(0.0, min(1.0, float(p)))\n",
    "    cv2.rectangle(img, (x0, y0), (x0+w, y0+h), bg, -1)\n",
    "    cv2.rectangle(img, (x0, y0), (x0+int(w*p), y0+h), fg, -1)\n",
    "    cv2.rectangle(img, (x0, y0), (x0+w, y0+h), (70,70,70), 1)\n",
    "\n",
    "def check_attribute_match(target_idx, pred_idx, locked_category):\n",
    "    if locked_category is None:\n",
    "        return pred_idx == target_idx\n",
    "    target_parsed = parse_class_name(CLASSES[target_idx])\n",
    "    pred_parsed = parse_class_name(CLASSES[pred_idx])\n",
    "    return target_parsed['category'] == pred_parsed['category'] == locked_category\n",
    "\n",
    "print(\"[OK] Helper functions ready (thr/EMA tuned)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fb4bebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FSL REAL-TIME TESTING\n",
      "============================================================\n",
      "\n",
      "CONTROLS:\n",
      "  E/R    : Navigate ←/→\n",
      "  ENTER  : Lock category / Select value\n",
      "  T      : Back to category selection\n",
      "  P      : Random\n",
      "  SPACE  : Start countdown\n",
      "  Q      : Quit\n",
      "\n",
      "AVAILABLE CATEGORIES: Color, Family, Numbers\n",
      "TOTAL GESTURES: 33\n",
      "CONFIDENCE THRESHOLD: 0.6\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "cv2.setNumThreads(1)\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "# States\n",
    "STATE_READY   = 0\n",
    "STATE_COUNTDOWN = 1\n",
    "STATE_ACTIVE  = 2\n",
    "STATE_RESULT  = 3\n",
    "\n",
    "COUNTDOWN_SEC   = 2.0\n",
    "RESULT_HOLD_SEC = 1.5\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))  \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n",
    "cap.set(cv2.CAP_PROP_FPS,          30)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE,    1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "# Runtime state\n",
    "state = STATE_READY\n",
    "target_idx = None\n",
    "consec_ok = 0\n",
    "consec_wrong = 0\n",
    "\n",
    "navigation_mode = 'category'   \n",
    "locked_category = None\n",
    "category_idx = 0\n",
    "value_idx = 0\n",
    "\n",
    "all_categories = get_all_categories()\n",
    "\n",
    "buf = np.zeros((SEQUENCE_LENGTH, FEATURE_DIM), np.float32)\n",
    "have = 0\n",
    "last_feat = None\n",
    "carry = 0\n",
    "idx = 0\n",
    "\n",
    "ema_logits = None\n",
    "t_last = time.time()\n",
    "fps_smoothed = None\n",
    "\n",
    "countdown_end_time = None\n",
    "result_end_time = None\n",
    "result_ok = False\n",
    "result_text = \"\"\n",
    "result_color = (255, 255, 255)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FSL REAL-TIME TESTING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nCONTROLS:\")\n",
    "print(\"  E/R    : Navigate ←/→\")\n",
    "print(\"  ENTER  : Lock category / Select value\")\n",
    "print(\"  T      : Back to category selection\")\n",
    "print(\"  P      : Random\")\n",
    "print(\"  SPACE  : Start countdown\")\n",
    "print(\"  Q      : Quit\")\n",
    "print(f\"\\nAVAILABLE CATEGORIES: {', '.join(all_categories)}\")\n",
    "print(f\"TOTAL GESTURES: {len(CLASSES)}\")\n",
    "print(f\"CONFIDENCE THRESHOLD: {BASE_THRESH}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed09bf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NAV] Locked to category: Color (13 values)\n",
      "[STATE] → COUNTDOWN\n",
      "[STATE] → ACTIVE (Target: Color_Black)\n",
      "[RESULT] ✅ Correct: Color_Black\n",
      "\n",
      "[INFO] Quitting...\n"
     ]
    }
   ],
   "source": [
    "with get_detector() as detector:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        proc_w, proc_h = 640, 360\n",
    "        small = cv2.resize(frame, (proc_w, proc_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if (idx % FRAME_STRIDE) != 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "        idx += 1\n",
    "\n",
    "        rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "        rgb.flags.writeable = False\n",
    "        try:\n",
    "            res = detector.process(rgb)\n",
    "        except Exception:\n",
    "            res = None\n",
    "\n",
    "        anchors = get_anchors(res)\n",
    "        L_pts, R_pts = get_lr_pts(res)\n",
    "        lf = 1.0 if L_pts is not None else 0.0\n",
    "        rf = 1.0 if R_pts is not None else 0.0\n",
    "        detected = (lf + rf) > 0.0\n",
    "\n",
    "        if detected:\n",
    "            feat = pack_feature_with_anchors(L_pts, R_pts, lf, rf, anchors)\n",
    "            last_feat = feat\n",
    "            carry = 0\n",
    "        else:\n",
    "            if (last_feat is not None) and (carry < MAX_CARRY_FRAMES):\n",
    "                feat = last_feat.copy()\n",
    "                if CARRY_NOISE > 0:\n",
    "                    noise = np.zeros_like(feat, dtype=np.float32)\n",
    "                    noise[:126] = np.random.normal(0.0, CARRY_NOISE, size=126).astype(np.float32)\n",
    "                    feat += noise\n",
    "                carry += 1\n",
    "            else:\n",
    "                feat = np.zeros((FEATURE_DIM,), np.float32)\n",
    "                \n",
    "        if have < SEQUENCE_LENGTH:\n",
    "            buf[have] = feat\n",
    "            have += 1\n",
    "        else:\n",
    "            buf[:-1] = buf[1:]\n",
    "            buf[-1] = feat\n",
    "\n",
    "        hud = frame.copy()\n",
    "        H, W = hud.shape[:2]\n",
    "        cv2.rectangle(hud, (0, 0), (W, 100), (25, 25, 25), -1)\n",
    "\n",
    "        # nav text\n",
    "        if navigation_mode == 'category':\n",
    "            mode_text = f\"Mode: SELECT CATEGORY ({len(all_categories)} options)\"\n",
    "            current_cat = all_categories[category_idx]\n",
    "            tgt_text = f\"Category: {current_cat} ({category_idx + 1}/{len(all_categories)})\"\n",
    "            hint_text = \"Press ENTER to lock this category\"\n",
    "        else:\n",
    "            current_cat = all_categories[category_idx]\n",
    "            values = get_values_in_category(current_cat)\n",
    "            mode_text = f\"Mode: {current_cat.upper()} VALUES ({len(values)} options)\"\n",
    "            current_val = values[value_idx]\n",
    "            tgt_text = f\"Value: {current_val} ({value_idx + 1}/{len(values)})\"\n",
    "            target_idx = get_class_index(current_cat, current_val)\n",
    "            hint_text = f\"Full: {CLASSES[target_idx]}\"\n",
    "\n",
    "        cv2.putText(hud, mode_text, (W-480, 25),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (180, 180, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(hud, tgt_text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 100), 2, cv2.LINE_AA)\n",
    "        cv2.putText(hud, hint_text, (10, 55),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1, cv2.LINE_AA)\n",
    "\n",
    "        # hand presence\n",
    "        flags_win = buf[:, FLAG_START:FLAG_END]\n",
    "        present_ratio = float((flags_win.sum(axis=1) > 0.0).mean()) if have > 0 else 0.0\n",
    "        hand_color = (100, 255, 100) if present_ratio > 0.25 else (120, 120, 120)\n",
    "        cv2.putText(hud, f\"Hands: {present_ratio*100:0.0f}%\", (W-200, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, hand_color, 2, cv2.LINE_AA)\n",
    "\n",
    "        # buffer progress\n",
    "        draw_progress_bar(hud, 10, 70, 240, 16, have/SEQUENCE_LENGTH, fg=(120, 220, 120))\n",
    "        cv2.putText(hud, f\"Buffer: {have}/{SEQUENCE_LENGTH}\", (260, 82),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (220, 220, 220), 1, cv2.LINE_AA)\n",
    "\n",
    "        # fps\n",
    "        if SHOW_FPS:\n",
    "            t_now = time.time()\n",
    "            fps = 1.0 / max(1e-6, (t_now - t_last))\n",
    "            t_last = t_now\n",
    "            fps_smoothed = fps if fps_smoothed is None else (0.8*fps_smoothed + 0.2*fps)\n",
    "            cv2.putText(hud, f\"{fps_smoothed:0.1f} FPS\", (W-120, 82),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (230, 230, 230), 2, cv2.LINE_AA)\n",
    "\n",
    "        # prediction\n",
    "        probs = None\n",
    "        pred_idx = None\n",
    "        pred_prob = 0.0\n",
    "\n",
    "        if have == SEQUENCE_LENGTH:\n",
    "            x = torch.from_numpy(buf[None, :, :]).to(device).float()\n",
    "            rm_np = (buf[:, FLAG_START:FLAG_END].sum(axis=1) > 0).astype(np.float32)\n",
    "            rm = torch.from_numpy(rm_np).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(x, reset_mask=rm).squeeze(0).cpu().numpy()\n",
    "\n",
    "            if ema_logits is None:\n",
    "                ema_logits = logits.copy()\n",
    "            else:\n",
    "                ema_logits = EMA_ALPHA * logits + (1.0 - EMA_ALPHA) * ema_logits\n",
    "\n",
    "            probs = softmax_np(ema_logits)\n",
    "            pred_idx = int(np.argmax(probs))\n",
    "            pred_prob = float(probs[pred_idx])\n",
    "\n",
    "        # Top-3 overlay\n",
    "        # draw_topk(hud, probs, CLASSES, x=10, y0=100, k=3, highlight_idx=pred_idx)\n",
    "\n",
    "        # state machine\n",
    "        now = time.time()\n",
    "        if state == STATE_READY:\n",
    "            if navigation_mode == 'category':\n",
    "                draw_center_text(hud, \"SELECT CATEGORY\", H//2 - 50, 1.2, (100, 220, 255), 3)\n",
    "                draw_center_text(hud, f\"{all_categories[category_idx]}\", H//2, 1.8, (100, 255, 100), 3)\n",
    "                draw_center_text(hud, \"E/R: Navigate | ENTER: Lock Category\", H//2 + 50, 0.7, (200, 200, 200), 2)\n",
    "            else:\n",
    "                draw_center_text(hud, \"SELECT VALUE\", H//2 - 50, 1.0, (255, 220, 100), 2)\n",
    "                values = get_values_in_category(all_categories[category_idx])\n",
    "                draw_center_text(hud, f\"{values[value_idx]}\", H//2, 1.8, (100, 255, 100), 3)\n",
    "                draw_center_text(hud, \"SPACE: Start | T: Back to Categories\", H//2 + 50, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        elif state == STATE_COUNTDOWN:\n",
    "            secs_left = countdown_end_time - now\n",
    "            if secs_left <= 0:\n",
    "                state = STATE_ACTIVE\n",
    "                consec_ok = consec_wrong = 0\n",
    "                buf.fill(0.0); have = 0; ema_logits = None\n",
    "                _beep(950, 120)\n",
    "                print(f\"[STATE] → ACTIVE (Target: {CLASSES[target_idx]})\")\n",
    "            else:\n",
    "                n = int(secs_left) + 1\n",
    "                draw_center_text(hud, \"Get ready...\", H//2 - 50, 1.2, (255, 225, 180), 3)\n",
    "                draw_center_text(hud, str(n), H//2 + 30, 3.0, (255, 235, 100), 4)\n",
    "\n",
    "        elif state == STATE_ACTIVE:\n",
    "            hands_ok = present_ratio > 0.25 and probs is not None\n",
    "            thr = get_threshold(pred_idx) if pred_idx is not None else BASE_THRESH\n",
    "\n",
    "            if hands_ok and target_idx is not None and pred_idx is not None:\n",
    "                if pred_prob >= thr:\n",
    "                    if check_attribute_match(target_idx, pred_idx, locked_category):\n",
    "                        consec_ok += 1; consec_wrong = 0\n",
    "                    else:\n",
    "                        consec_wrong += 1; consec_ok = 0\n",
    "                else:\n",
    "                    consec_ok = consec_wrong = 0\n",
    "\n",
    "                prog = max(consec_ok, consec_wrong) / max(1, N_CONSEC)\n",
    "                draw_progress_bar(hud, (W-340)//2, 110, 340, 18, prog,\n",
    "                                  fg=(0, 220, 0) if consec_ok > consec_wrong else (0, 100, 255))\n",
    "\n",
    "                tgt_name  = parse_class_name(CLASSES[target_idx])['value']\n",
    "                pred_name = parse_class_name(CLASSES[pred_idx])['value'] if pred_idx is not None else \"…\"\n",
    "                draw_center_text(hud, f\"Target: {tgt_name}  |  Pred: {pred_name} ({pred_prob:.2f})\",\n",
    "                                 150, 0.9, (230, 230, 230), 2)\n",
    "\n",
    "                if consec_ok >= N_CONSEC:\n",
    "                    state = STATE_RESULT\n",
    "                    result_ok = True\n",
    "                    result_text = \"✅ CORRECT!\"\n",
    "                    result_color = (0, 255, 0)\n",
    "                    result_end_time = now + RESULT_HOLD_SEC\n",
    "                    _beep(1000, 120)\n",
    "                    print(f\"[RESULT] ✅ Correct: {CLASSES[target_idx]}\")\n",
    "                elif consec_wrong >= N_CONSEC:\n",
    "                    state = STATE_RESULT\n",
    "                    result_ok = False\n",
    "                    result_text = \"❌ WRONG\"\n",
    "                    result_color = (0, 100, 255)\n",
    "                    result_end_time = now + RESULT_HOLD_SEC\n",
    "                    _beep(450, 150)\n",
    "                    print(f\"[RESULT] ❌ Wrong: Expected {CLASSES[target_idx]}, got {CLASSES[pred_idx]}\")\n",
    "            else:\n",
    "                draw_center_text(hud, \"Show your sign clearly!\", 150, 1.1, (255, 255, 100), 3)\n",
    "\n",
    "        elif state == STATE_RESULT:\n",
    "            draw_center_text(hud, result_text, H//2 - 20, 1.8, result_color, 4)\n",
    "            if not result_ok and pred_idx is not None:\n",
    "                pred_name = parse_class_name(CLASSES[pred_idx])['value']\n",
    "                draw_center_text(hud, f\"Detected: {pred_name}\", H//2 + 40, 1.0, (200, 200, 200), 2)\n",
    "\n",
    "            if now >= result_end_time:\n",
    "                state = STATE_READY\n",
    "                consec_ok = consec_wrong = 0\n",
    "                buf.fill(0.0); have = 0; ema_logits = None\n",
    "                print(\"[STATE] → READY\")\n",
    "\n",
    "        # show window\n",
    "        cv2.imshow(\"FSL Real-time Testing\", hud)\n",
    "\n",
    "        # keys\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"\\n[INFO] Quitting...\")\n",
    "            break\n",
    "\n",
    "        if key in [ord('t'), ord('T')]:\n",
    "            if navigation_mode == 'value':\n",
    "                navigation_mode = 'category'\n",
    "                locked_category = None\n",
    "                target_idx = None\n",
    "                print(f\"\\n[NAV] Back to CATEGORY selection\")\n",
    "\n",
    "        if key == 13:  # Enter\n",
    "            if navigation_mode == 'category':\n",
    "                navigation_mode = 'value'\n",
    "                locked_category = all_categories[category_idx]\n",
    "                value_idx = 0\n",
    "                values = get_values_in_category(locked_category)\n",
    "                target_idx = get_class_index(locked_category, values[value_idx])\n",
    "                print(f\"\\n[NAV] Locked to category: {locked_category} ({len(values)} values)\")\n",
    "\n",
    "        if key in [ord('e'), ord('E')]:\n",
    "            if navigation_mode == 'category':\n",
    "                category_idx = (category_idx - 1) % len(all_categories)\n",
    "                print(f\"\\n[NAV] ← Category: {all_categories[category_idx]}\")\n",
    "            else:\n",
    "                values = get_values_in_category(all_categories[category_idx])\n",
    "                value_idx = (value_idx - 1) % len(values)\n",
    "                target_idx = get_class_index(all_categories[category_idx], values[value_idx])\n",
    "                print(f\"\\n[NAV] ← Value: {values[value_idx]}\")\n",
    "\n",
    "        if key in [ord('r'), ord('R')]:\n",
    "            if navigation_mode == 'category':\n",
    "                category_idx = (category_idx + 1) % len(all_categories)\n",
    "                print(f\"\\n[NAV] → Category: {all_categories[category_idx]}\")\n",
    "            else:\n",
    "                values = get_values_in_category(all_categories[category_idx])\n",
    "                value_idx = (value_idx + 1) % len(values)\n",
    "                target_idx = get_class_index(all_categories[category_idx], values[value_idx])\n",
    "                print(f\"\\n[NAV] → Value: {values[value_idx]}\")\n",
    "\n",
    "        if key in [ord('p'), ord('P')]:\n",
    "            if navigation_mode == 'category':\n",
    "                category_idx = random.randrange(len(all_categories))\n",
    "                print(f\"\\n[NAV] 🎲 Random category: {all_categories[category_idx]}\")\n",
    "            else:\n",
    "                values = get_values_in_category(all_categories[category_idx])\n",
    "                value_idx = random.randrange(len(values))\n",
    "                target_idx = get_class_index(all_categories[category_idx], values[value_idx])\n",
    "                print(f\"\\n[NAV] 🎲 Random value: {values[value_idx]}\")\n",
    "\n",
    "        if key == ord(' '):\n",
    "            if navigation_mode == 'value' and target_idx is not None and state == STATE_READY:\n",
    "                countdown_end_time = now + COUNTDOWN_SEC\n",
    "                state = STATE_COUNTDOWN\n",
    "                _beep(700, 120)\n",
    "                print(f\"[STATE] → COUNTDOWN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371dae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Testing session ended\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\n[INFO] Testing session ended\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaEnviTensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
