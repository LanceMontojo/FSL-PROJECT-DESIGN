{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a6d24e",
   "metadata": {},
   "source": [
    "# Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cadfef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, cv2, tqdm, shutil\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36648228",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c2fec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared augmented .npy files.\n"
     ]
    }
   ],
   "source": [
    "OUT = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "for p in OUT.rglob(\"*.npy\"):\n",
    "    p.unlink()  # delete all old augmented npy files\n",
    "print(\"Cleared augmented .npy files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9600026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2025)\n",
    "NUM_LM = 21 # number of landmarks per hand\n",
    "FEATURE_COORDS = 42 * 3 # 2 hands * 21 landmarks * 3 coords (x,y,z)\n",
    "APPEND_FLAGS = True\n",
    "FEATURE_DIM = FEATURE_COORDS + (2 if APPEND_FLAGS else 0) # 128 if appending presence flags\n",
    "CLIP_LIMIT = 5.0 # max abs value for coords\n",
    "\n",
    "INPUT_DIR = r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KEYPOINTS\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SEQUENCE_LENGTH = 48\n",
    "OVERWRITE = True  # True = regenerate; False = keep existing\n",
    "PAD_MODE = \"zeros\"\n",
    "RIGHT_HAND_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5058818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f32(x):\n",
    "    return np.asarray(x, dtype=np.float32)\n",
    "\n",
    "def split_coords_flags(seq):\n",
    "    \"\"\"(T,D)-> coords(T,42,3), flags(T,2). Fill zeros if flags absent.\"\"\"\n",
    "    seq = _f32(seq)\n",
    "    coords = seq[:, :FEATURE_COORDS].reshape(len(seq), 42, 3)\n",
    "    if APPEND_FLAGS and seq.shape[1] >= FEATURE_COORDS + 2:\n",
    "        flags = seq[:, FEATURE_COORDS:FEATURE_COORDS+2]\n",
    "    else:\n",
    "        flags = np.zeros((len(seq), 2), np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "def combine_coords_flags(coords, flags):\n",
    "    flat = coords.reshape(len(coords), FEATURE_COORDS)\n",
    "    if APPEND_FLAGS:\n",
    "        return np.concatenate([flat, flags.astype(np.float32)], axis=1)\n",
    "    return flat\n",
    "\n",
    "def swap_left_right(coords, flags):\n",
    "    \"\"\"Swap hands 0..20 <-> 21..41 and flags [L,R]->[R,L].\"\"\"\n",
    "    left  = coords[:, :NUM_LM, :].copy()\n",
    "    right = coords[:, NUM_LM:, :].copy()\n",
    "    coords[:, :NUM_LM, :] = right\n",
    "    coords[:, NUM_LM:, :] = left\n",
    "    if flags.shape[1] == 2:\n",
    "        flags = flags[:, ::-1]\n",
    "    return coords, flags\n",
    "\n",
    "# -------- temporal utilities (mirror extraction) --------\n",
    "def _motion_mag(coords: np.ndarray) -> np.ndarray:\n",
    "    v = np.diff(coords, axis=0)\n",
    "    return np.linalg.norm(v, axis=(1, 2))\n",
    "\n",
    "def trim_idle_edges(coords: np.ndarray, flags: np.ndarray, max_idle_edge=12, eps=5e-4):\n",
    "    \"\"\"Same behavior as extractor: trim long low-motion stretches at start/end.\"\"\"\n",
    "    T = coords.shape[0]\n",
    "    if T <= 2:\n",
    "        return coords, flags\n",
    "    v = np.diff(coords, axis=0)\n",
    "    m = np.linalg.norm(v, axis=(1, 2))           # (T-1,)\n",
    "    m_full = np.r_[m[0], m, m[-1]] if len(m) > 1 else np.zeros(T, dtype=np.float32)\n",
    "    active_idx = np.where(m_full > eps)[0]\n",
    "    if len(active_idx) == 0:\n",
    "        single = coords[-1:][:1]\n",
    "        return np.repeat(single, repeats=min(T, 1), axis=0), flags[: min(T, 1)]\n",
    "    start = max(0, active_idx[0] - 1)\n",
    "    end   = min(T, active_idx[-1] + 1)\n",
    "    if start > max_idle_edge: start = max_idle_edge\n",
    "    if (T - end) > max_idle_edge: end = T - max_idle_edge\n",
    "    end = max(end, start + 1)\n",
    "    return coords[start:end], flags[start:end]\n",
    "\n",
    "def _tail_is_frozen(coords: np.ndarray, k=6, eps=5e-4) -> bool:\n",
    "    k = min(k, coords.shape[0]-1) if coords.shape[0] > 1 else 1\n",
    "    tail = coords[-(k+1):]\n",
    "    diffs = np.abs(np.diff(tail, axis=0)).mean()\n",
    "    return bool(diffs < eps)\n",
    "\n",
    "def _defrost_tail(coords: np.ndarray, strength=0.25):\n",
    "    T = coords.shape[0]\n",
    "    if T < 4:\n",
    "        return coords\n",
    "    seg = max(3, int(T * strength))\n",
    "    a0 = T - seg\n",
    "    a1 = T - 1\n",
    "    if a0 >= a1:\n",
    "        return coords\n",
    "    ramp = np.linspace(0.0, 1.0, seg, dtype=np.float32)[:, None, None]\n",
    "    mid0, mid1 = max(0, T//3), min(T-1, 2*T//3)\n",
    "    mean_v = (coords[mid1] - coords[mid0]) / max(1, (mid1 - mid0))\n",
    "    coords[a0:T] = coords[a0:T] + 0.02 * ramp * mean_v\n",
    "    return coords\n",
    "\n",
    "def _resample_coords_flags(coords: np.ndarray, flags: np.ndarray, target_len: int):\n",
    "    \"\"\"Linear resample coords; nearest-like for flags (re-binarize).\"\"\"\n",
    "    T = coords.shape[0]\n",
    "    if T == target_len:\n",
    "        return coords.astype(np.float32), flags.astype(np.float32)\n",
    "    idx = np.linspace(0, T - 1, num=target_len)\n",
    "    lo = np.floor(idx).astype(int)\n",
    "    hi = np.clip(lo + 1, 0, T - 1)\n",
    "    w  = (idx - lo)[:, None, None]\n",
    "    coords_out = (1 - w) * coords[lo] + w * coords[hi]\n",
    "    flags_out  = flags[np.round(idx).astype(int)]\n",
    "    return coords_out.astype(np.float32), flags_out.astype(np.float32)\n",
    "\n",
    "def temporal_fix(seq: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    EXACT match to extractor:\n",
    "      1) split -> 2) trim idle edges -> 3) resample -> 4) defrost tail if frozen -> 5) combine\n",
    "    \"\"\"\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    coords, flags = trim_idle_edges(coords, flags, max_idle_edge=12, eps=5e-4)\n",
    "    coords, flags = _resample_coords_flags(coords, flags, target_len)\n",
    "    if _tail_is_frozen(coords, k=6, eps=5e-4):\n",
    "        coords = _defrost_tail(coords, strength=0.25)\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "# -------- geometric / noise (no temporal cropping here) --------\n",
    "def _clamp(coords):\n",
    "    return np.clip(coords, -CLIP_LIMIT, CLIP_LIMIT).astype(np.float32)\n",
    "\n",
    "def add_noise(seq, sigma_xy=0.008, sigma_z=0.004):\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    noise = rng.normal(0, [sigma_xy, sigma_xy, sigma_z], size=coords.shape).astype(np.float32)\n",
    "    coords = _clamp(coords + noise)\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "def scale_translate(seq, scale_range=(0.9,1.1), translate_xy=(-0.08,0.08)):\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    s  = rng.uniform(*scale_range)\n",
    "    tx = rng.uniform(*translate_xy)\n",
    "    ty = rng.uniform(*translate_xy)\n",
    "    coords = coords * np.array([s,s,s], np.float32)\n",
    "    coords[...,0] += tx\n",
    "    coords[...,1] += ty\n",
    "    coords = _clamp(coords)\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "def rotate(seq, angle_range=(-10,10)):\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    ang = np.deg2rad(rng.uniform(*angle_range))\n",
    "    c, s = np.cos(ang), np.sin(ang)\n",
    "    R = np.array([[c,-s],[s,c]], np.float32)\n",
    "    coords[..., :2] = coords[..., :2] @ R.T\n",
    "    coords = _clamp(coords)\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "def flip(seq):\n",
    "    \"\"\"Mirror X + swap hands + swap flags.\"\"\"\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    coords[...,0] *= -1.0\n",
    "    coords, flags = swap_left_right(coords, flags)\n",
    "    coords = _clamp(coords)\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "def landmark_dropout(seq, p=0.03):\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    mask = rng.random(coords.shape[:-1]) < p  # (T,42)\n",
    "    coords[mask] = 0.0\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "def hand_dropout(seq, p=0.10):\n",
    "    seq = _f32(seq).copy()\n",
    "    coords, flags = split_coords_flags(seq)\n",
    "    if rng.random() > p:\n",
    "        return combine_coords_flags(coords, flags)\n",
    "    drop_left = rng.random() < 0.5\n",
    "    if drop_left:\n",
    "        coords[:, :NUM_LM, :] = 0.0\n",
    "        flags[:,0] = 0.0\n",
    "    else:\n",
    "        coords[:, NUM_LM:, :] = 0.0\n",
    "        flags[:,1] = 0.0\n",
    "    return combine_coords_flags(coords, flags)\n",
    "\n",
    "# ---- augmentation heads that PRESERVE temporal_fix result ----\n",
    "def augment_from_fixed(seq_fixed):\n",
    "    \"\"\"\n",
    "    seq_fixed: already temporal_fixed to SEQUENCE_LENGTH.\n",
    "    Apply geometric/noise-only augs; length stays the same.\n",
    "    \"\"\"\n",
    "    s = seq_fixed\n",
    "    s = rotate(s)\n",
    "    s = scale_translate(s)\n",
    "    if rng.random() < 0.9: s = add_noise(s, sigma_xy=0.008, sigma_z=0.004)\n",
    "    if rng.random() < 0.4: s = landmark_dropout(s, p=0.03)\n",
    "    if rng.random() < 0.2: s = hand_dropout(s, p=0.10)\n",
    "    # safety: ensure flags are 0/1\n",
    "    if s.shape[1] >= FEATURE_COORDS + 2:\n",
    "        s[:, FEATURE_COORDS:FEATURE_COORDS+2] = (s[:, FEATURE_COORDS:FEATURE_COORDS+2] >= 0.5).astype(np.float32)\n",
    "    return _f32(s)\n",
    "\n",
    "def augment_from_fixed_with_flip(seq_fixed):\n",
    "    s = augment_from_fixed(seq_fixed)\n",
    "    s = flip(s)\n",
    "    if s.shape[1] >= FEATURE_COORDS + 2:\n",
    "        s[:, FEATURE_COORDS:FEATURE_COORDS+2] = (s[:, FEATURE_COORDS:FEATURE_COORDS+2] >= 0.5).astype(np.float32)\n",
    "    return _f32(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0fa46c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0.npy -> 8 sequences saved\n",
      "Processed 1.npy -> 8 sequences saved\n",
      "Processed 10.npy -> 8 sequences saved\n",
      "Processed 11.npy -> 8 sequences saved\n",
      "Processed 12.npy -> 8 sequences saved\n",
      "Processed 13.npy -> 8 sequences saved\n",
      "Processed 14.npy -> 8 sequences saved\n",
      "Processed 15.npy -> 8 sequences saved\n",
      "Processed 16.npy -> 8 sequences saved\n",
      "Processed 17.npy -> 8 sequences saved\n",
      "Processed 18.npy -> 8 sequences saved\n",
      "Processed 19.npy -> 8 sequences saved\n",
      "Processed 2.npy -> 8 sequences saved\n",
      "Processed 20.npy -> 8 sequences saved\n",
      "Processed 3.npy -> 8 sequences saved\n",
      "Processed 4.npy -> 8 sequences saved\n",
      "Processed 5.npy -> 8 sequences saved\n",
      "Processed 6.npy -> 8 sequences saved\n",
      "Processed 7.npy -> 8 sequences saved\n",
      "Processed 8.npy -> 8 sequences saved\n",
      "Processed 9.npy -> 8 sequences saved\n",
      "Processed 0.npy -> 8 sequences saved\n",
      "Processed 1.npy -> 8 sequences saved\n",
      "Processed 10.npy -> 8 sequences saved\n",
      "Processed 11.npy -> 8 sequences saved\n",
      "Processed 12.npy -> 8 sequences saved\n",
      "Processed 13.npy -> 8 sequences saved\n",
      "Processed 14.npy -> 8 sequences saved\n",
      "Processed 15.npy -> 8 sequences saved\n",
      "Processed 16.npy -> 8 sequences saved\n",
      "Processed 17.npy -> 8 sequences saved\n",
      "Processed 18.npy -> 8 sequences saved\n",
      "Processed 19.npy -> 8 sequences saved\n",
      "Processed 2.npy -> 8 sequences saved\n",
      "Processed 20.npy -> 8 sequences saved\n",
      "Processed 3.npy -> 8 sequences saved\n",
      "Processed 4.npy -> 8 sequences saved\n",
      "Processed 5.npy -> 8 sequences saved\n",
      "Processed 6.npy -> 8 sequences saved\n",
      "Processed 7.npy -> 8 sequences saved\n",
      "Processed 8.npy -> 8 sequences saved\n",
      "Processed 9.npy -> 8 sequences saved\n",
      "Processed 0.npy -> 8 sequences saved\n",
      "Processed 1.npy -> 8 sequences saved\n",
      "Processed 10.npy -> 8 sequences saved\n",
      "Processed 11.npy -> 8 sequences saved\n",
      "Processed 12.npy -> 8 sequences saved\n",
      "Processed 13.npy -> 8 sequences saved\n",
      "Processed 14.npy -> 8 sequences saved\n",
      "Processed 15.npy -> 8 sequences saved\n",
      "Processed 16.npy -> 8 sequences saved\n",
      "Processed 17.npy -> 8 sequences saved\n",
      "Processed 18.npy -> 8 sequences saved\n",
      "Processed 19.npy -> 8 sequences saved\n",
      "Processed 2.npy -> 8 sequences saved\n",
      "Processed 20.npy -> 8 sequences saved\n",
      "Processed 21.npy -> 8 sequences saved\n",
      "Processed 3.npy -> 8 sequences saved\n",
      "Processed 4.npy -> 8 sequences saved\n",
      "Processed 5.npy -> 8 sequences saved\n",
      "Processed 6.npy -> 8 sequences saved\n",
      "Processed 7.npy -> 8 sequences saved\n",
      "Processed 8.npy -> 8 sequences saved\n",
      "Processed 9.npy -> 8 sequences saved\n",
      "Processed 0.npy -> 8 sequences saved\n",
      "Processed 1.npy -> 8 sequences saved\n",
      "Processed 10.npy -> 8 sequences saved\n",
      "Processed 11.npy -> 8 sequences saved\n",
      "Processed 12.npy -> 8 sequences saved\n",
      "Processed 13.npy -> 8 sequences saved\n",
      "Processed 14.npy -> 8 sequences saved\n",
      "Processed 15.npy -> 8 sequences saved\n",
      "Processed 16.npy -> 8 sequences saved\n",
      "Processed 17.npy -> 8 sequences saved\n",
      "Processed 18.npy -> 8 sequences saved\n",
      "Processed 19.npy -> 8 sequences saved\n",
      "Processed 2.npy -> 8 sequences saved\n",
      "Processed 3.npy -> 8 sequences saved\n",
      "Processed 4.npy -> 8 sequences saved\n",
      "Processed 5.npy -> 8 sequences saved\n",
      "Processed 6.npy -> 8 sequences saved\n",
      "Processed 7.npy -> 8 sequences saved\n",
      "Processed 8.npy -> 8 sequences saved\n",
      "Processed 9.npy -> 8 sequences saved\n",
      "Processed 0.npy -> 8 sequences saved\n",
      "Processed 1.npy -> 8 sequences saved\n",
      "Processed 10.npy -> 8 sequences saved\n",
      "Processed 11.npy -> 8 sequences saved\n",
      "Processed 12.npy -> 8 sequences saved\n",
      "Processed 13.npy -> 8 sequences saved\n",
      "Processed 14.npy -> 8 sequences saved\n",
      "Processed 15.npy -> 8 sequences saved\n",
      "Processed 16.npy -> 8 sequences saved\n",
      "Processed 17.npy -> 8 sequences saved\n",
      "Processed 18.npy -> 8 sequences saved\n",
      "Processed 19.npy -> 8 sequences saved\n",
      "Processed 2.npy -> 8 sequences saved\n",
      "Processed 3.npy -> 8 sequences saved\n",
      "Processed 4.npy -> 8 sequences saved\n",
      "Processed 5.npy -> 8 sequences saved\n",
      "Processed 6.npy -> 8 sequences saved\n",
      "Processed 7.npy -> 8 sequences saved\n",
      "Processed 8.npy -> 8 sequences saved\n",
      "Processed 9.npy -> 8 sequences saved\n",
      "Offline augmentation complete!\n"
     ]
    }
   ],
   "source": [
    "classes = [d for d in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, d))]\n",
    "\n",
    "for action in classes:\n",
    "    in_dir  = os.path.join(INPUT_DIR, action)\n",
    "    out_dir = os.path.join(OUTPUT_DIR, action)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(in_dir):\n",
    "        if not fname.endswith(\".npy\"):\n",
    "            continue\n",
    "        src = os.path.join(in_dir, fname)\n",
    "        base = fname[:-4]\n",
    "\n",
    "        # output paths\n",
    "        orig_out  = os.path.join(out_dir, f\"{base}.npy\")\n",
    "        aug_paths = [os.path.join(out_dir, f\"{base}_aug{i}.npy\") for i in range(1,6)]\n",
    "\n",
    "        if (not OVERWRITE) and os.path.exists(orig_out) and all(os.path.exists(p) for p in aug_paths):\n",
    "            print(f\"Skipped {fname} (already augmented)\")\n",
    "            continue\n",
    "\n",
    "        arr = _f32(np.load(src, allow_pickle=False))\n",
    "        # normalize feature width to match APPEND_FLAGS setting\n",
    "        if arr.shape[1] == FEATURE_COORDS and APPEND_FLAGS:\n",
    "            zf = np.zeros((len(arr), 2), np.float32)\n",
    "            arr = np.concatenate([arr, zf], axis=1)\n",
    "        elif arr.shape[1] == FEATURE_COORDS + 2 and not APPEND_FLAGS:\n",
    "            arr = arr[:, :FEATURE_COORDS]\n",
    "        elif arr.shape[1] not in (FEATURE_COORDS, FEATURE_COORDS + 2):\n",
    "            print(f\"[skip] {fname}: unexpected D={arr.shape[1]}\")\n",
    "            continue\n",
    "\n",
    "        orig_seq = temporal_fix(arr, SEQUENCE_LENGTH)\n",
    "\n",
    "        seqs = [orig_seq]  # always keep original\n",
    "        for _ in range(5):\n",
    "            seqs.append(augment_from_fixed(orig_seq))\n",
    "\n",
    "        if not RIGHT_HAND_ONLY:\n",
    "            # LEFT/RIGHT symmetry augmentation only if deployment allows it\n",
    "            forced_flip = flip(orig_seq)\n",
    "            if forced_flip.shape[1] >= FEATURE_COORDS + 2:\n",
    "                forced_flip[:, FEATURE_COORDS:FEATURE_COORDS+2] = (forced_flip[:, FEATURE_COORDS:FEATURE_COORDS+2] >= 0.5).astype(np.float32)\n",
    "            seqs.append(forced_flip)\n",
    "\n",
    "        # Balanced randomized augmentations (no re-trim; preserve time structure)\n",
    "        seqs.append(augment_from_fixed(orig_seq))\n",
    "        seqs.append(augment_from_fixed(orig_seq))\n",
    "\n",
    "        if not RIGHT_HAND_ONLY:\n",
    "            seqs.append(augment_from_fixed_with_flip(orig_seq))\n",
    "            seqs.append(augment_from_fixed_with_flip(orig_seq))\n",
    "\n",
    "        # Save\n",
    "        for i, s in enumerate(seqs):\n",
    "            save_path = orig_out if i == 0 else os.path.join(out_dir, f\"{base}_aug{i}.npy\")\n",
    "            np.save(save_path, s.astype(np.float32))\n",
    "\n",
    "        print(f\"Processed {fname} -> {len(seqs)} sequences saved\")\n",
    "\n",
    "print(\"Offline augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5162d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repair done. Fixed 0 files; total flagged: 0\n"
     ]
    }
   ],
   "source": [
    "# Set DATA_PATH to the directory you want to repair (augmented by default)\n",
    "DATA_PATH = Path(OUTPUT_DIR)\n",
    "\n",
    "# Build the 'bad' list (class, filename, shape, dtype) for files with wrong shape/flags\n",
    "bad = []\n",
    "for cls_dir in DATA_PATH.iterdir():\n",
    "    if not cls_dir.is_dir():\n",
    "        continue\n",
    "    for npy in cls_dir.glob(\"*.npy\"):\n",
    "        try:\n",
    "            arr = np.load(npy, allow_pickle=False)\n",
    "        except Exception as e:\n",
    "            bad.append((cls_dir.name, npy.name, \"unreadable\", str(e)))\n",
    "            continue\n",
    "\n",
    "        # ensure 2D\n",
    "        if arr.ndim != 2:\n",
    "            arr = np.reshape(arr, (arr.shape[0], -1))\n",
    "\n",
    "        shape_ok = (arr.shape[1] in (FEATURE_COORDS, FEATURE_DIM)) and (arr.shape[0] == SEQUENCE_LENGTH)\n",
    "        flags_ok = True\n",
    "        if arr.shape[1] >= FEATURE_DIM:\n",
    "            fl = arr[:, FEATURE_COORDS:FEATURE_COORDS+2]\n",
    "            flags_ok = np.isin(fl, [0.0, 1.0]).all()\n",
    "\n",
    "        if (not shape_ok) or (not flags_ok):\n",
    "            bad.append((cls_dir.name, npy.name, arr.shape, str(arr.dtype)))\n",
    "\n",
    "# Repair pass\n",
    "for cls, name, shp, dt in bad:\n",
    "    p = DATA_PATH / cls / name\n",
    "    try:\n",
    "        repair_file(p)\n",
    "        print(f\"[fixed] {cls}/{name} from shape={shp}, dtype={dt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[fail ] {cls}/{name}: {e}\")\n",
    "\n",
    "print(f\"Repair done. Fixed {sum('fixed' in line for line in map(str, bad))} files; total flagged: {len(bad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e9d8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are bad files from previous cells, fix them then rerun cell 4\n",
    "def fix_length(seq, target=SEQUENCE_LENGTH):\n",
    "    seq = np.asarray(seq, dtype=np.float32)\n",
    "    T, D = seq.shape\n",
    "    if T == target:\n",
    "        out = seq\n",
    "    else:\n",
    "        idx = np.linspace(0, T-1, target)\n",
    "        lo = np.floor(idx).astype(int)\n",
    "        hi = np.minimum(lo+1, T-1)\n",
    "        w  = (idx - lo)[:, None]\n",
    "        out = (1-w)*seq[lo] + w*seq[hi]\n",
    "    if out.shape[1] >= FEATURE_DIM:\n",
    "        out[:, FEATURE_COORDS:FEATURE_COORDS+2] = (out[:, FEATURE_COORDS:FEATURE_COORDS+2] >= 0.5).astype(np.float32)\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "def repair_file(path: Path):\n",
    "    arr = np.load(path, allow_pickle=False)\n",
    "    if arr.ndim != 2:\n",
    "        arr = np.reshape(arr, (arr.shape[0], -1)).astype(np.float32)\n",
    "    if arr.shape[1] == FEATURE_COORDS and APPEND_FLAGS:\n",
    "        zf = np.zeros((arr.shape[0], 2), np.float32)\n",
    "        arr = np.concatenate([arr.astype(np.float32), zf], axis=1)\n",
    "    elif arr.shape[1] > FEATURE_DIM:\n",
    "        arr = arr[:, :FEATURE_DIM].astype(np.float32)\n",
    "    elif arr.shape[1] < FEATURE_DIM:\n",
    "        padw = FEATURE_DIM - arr.shape[1]\n",
    "        arr = np.concatenate([arr.astype(np.float32), np.zeros((arr.shape[0], padw), np.float32)], axis=1)\n",
    "    arr = fix_length(arr, SEQUENCE_LENGTH)\n",
    "    np.save(path, arr.astype(np.float32))\n",
    "\n",
    "# run repair on the bad list from step 1\n",
    "for cls, name, shp, dt in bad:\n",
    "    p = Path(DATA_PATH, cls, name)\n",
    "    try:\n",
    "        repair_file(p)\n",
    "        print(f\"[fixed] {cls}/{name} from shape={shp}, dtype={dt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[fail ] {cls}/{name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57c793a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-class augmented counts: {\"Don't Understand\": 168, 'Good Afternoon': 168, 'Good Evening': 176, 'Good Morning': 160, 'Hello': 160, '_webcam_captures': 0}\n",
      "total augmented .npy files: 832\n",
      "unique shapes found: {(48, 128)}\n",
      "left_present fraction: 0.011318108974358974\n",
      "right_present fraction: 0.5452974759615384\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: summarize augmented outputs\n",
    "import os, numpy as np\n",
    "# Use OUTPUT_DIR if defined in the notebook, otherwise fall back to the known path\n",
    "try:\n",
    "    OUTPUT_DIR\n",
    "except NameError:\n",
    "    OUTPUT_DIR = r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\"\n",
    "\n",
    "classes = [d for d in os.listdir(OUTPUT_DIR) if os.path.isdir(os.path.join(OUTPUT_DIR, d))]\n",
    "per_class = {}\n",
    "shapes = set()\n",
    "flag_counts = { 'left': 0, 'right': 0, 'frames': 0 }\n",
    "total = 0\n",
    "for cls in classes:\n",
    "    folder = os.path.join(OUTPUT_DIR, cls)\n",
    "    cnt = 0\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith('.npy'):\n",
    "            cnt += 1\n",
    "            arr = np.load(os.path.join(folder, f))\n",
    "            shapes.add(tuple(arr.shape))\n",
    "            if arr.size:\n",
    "                flags = np.array(arr)[:, -2:]\n",
    "                flag_counts['left'] += flags[:,0].sum()\n",
    "                flag_counts['right'] += flags[:,1].sum()\n",
    "                flag_counts['frames'] += flags.shape[0]\n",
    "    per_class[cls] = cnt\n",
    "    total += cnt\n",
    "\n",
    "print('per-class augmented counts:', per_class)\n",
    "print('total augmented .npy files:', total)\n",
    "print('unique shapes found:', shapes)\n",
    "if flag_counts['frames']:\n",
    "    print('left_present fraction:', flag_counts['left'] / flag_counts['frames'])\n",
    "    print('right_present fraction:', flag_counts['right'] / flag_counts['frames'])\n",
    "else:\n",
    "    print('no frames found to compute flag stats')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "006d3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair counts: {(0, 0): 2215, (1, 0): 51, (0, 1): 2720, (1, 1): 6}\n",
      "columns identical? -> False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\"\n",
    "classes = [\"Good Morning\",\"Good Afternoon\",\"Good Evening\",\"Hello\",\"Don't Understand\"]\n",
    "\n",
    "pairs = { (0,0):0, (1,0):0, (0,1):0, (1,1):0 }\n",
    "same_cols = True\n",
    "total = 0\n",
    "\n",
    "for cls in classes:\n",
    "    for p in Path(DATA_PATH, cls).glob(\"*.npy\"):\n",
    "        if \"_aug\" in p.stem: \n",
    "            continue\n",
    "        arr = np.load(p, allow_pickle=False).astype(np.float32)\n",
    "        flags = arr[:, -2:].astype(np.int32)\n",
    "        total += len(flags)\n",
    "        # count pairs\n",
    "        for a,b in flags:\n",
    "            pairs[(a,b)] += 1\n",
    "        # check if columns are identical\n",
    "        if same_cols and not (flags[:,0] == flags[:,1]).all():\n",
    "            same_cols = False\n",
    "\n",
    "print(\"pair counts:\", pairs)\n",
    "print(\"columns identical? ->\", same_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active frames: 22181\n",
      "left_present (active only): 0.02037780082052207\n",
      "right_present (active only): 0.9817862134259051\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\"\n",
    "left = right = active = 0\n",
    "files = frames = 0\n",
    "for p in Path(DATA_PATH).rglob(\"*.npy\"):\n",
    "    arr = np.load(p, allow_pickle=False).astype(np.float32)\n",
    "    flags = arr[:, -2:]\n",
    "    active_mask = (flags.sum(axis=1) > 0)\n",
    "    active += active_mask.sum()\n",
    "    left  += flags[active_mask, 0].sum()\n",
    "    right += flags[active_mask, 1].sum()\n",
    "    files += 1; frames += len(flags)\n",
    "\n",
    "print(\"active frames:\", active)\n",
    "print(\"left_present (active only):\", left/active if active else 0.0)\n",
    "print(\"right_present (active only):\", right/active if active else 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d433e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] temporal_plausibility_bad= 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, random, glob, os\n",
    "\n",
    "aug_paths = glob.glob(os.path.join(OUTPUT_DIR, \"**\", \"*.npy\"), recursive=True)\n",
    "assert aug_paths, \"No augmented .npy found.\"\n",
    "\n",
    "def monotonic_time_ops_ok(seq_before, seq_after):\n",
    "    # crude: correlation of frame index vs DTW alignment should be positive on average\n",
    "    # here: just check that first/last frames don't swap (cheap proxy)\n",
    "    return np.linalg.norm(seq_after[0]-seq_before[0]) < np.linalg.norm(seq_after[-1]-seq_before[0])\n",
    "\n",
    "bad = 0\n",
    "for p in random.sample(aug_paths, min(50, len(aug_paths))):\n",
    "    a = np.load(p)\n",
    "    assert a.ndim == 2 and a.shape[0] >= 16, f\"{p}: shape off {a.shape}\"\n",
    "    C = a[:, :126].reshape(a.shape[0], 42, 3)\n",
    "    # cheap “temporal plausibility”: middle shouldn’t equal last\n",
    "    if np.allclose(C[len(C)//2], C[-1]):\n",
    "        bad += 1\n",
    "print(f\"[OK] temporal_plausibility_bad= {bad}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06de5da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-class augmented counts: {\"Don't Understand\": 168, 'Good Afternoon': 168, 'Good Evening': 176, 'Good Morning': 160, 'Hello': 160}\n",
      "total augmented .npy files: 832\n"
     ]
    }
   ],
   "source": [
    "import glob, numpy as np, os, random\n",
    "paths = glob.glob(os.path.join(OUTPUT_DIR, \"**\", \"*.npy\"), recursive=True)\n",
    "assert paths, \"No augmented files written.\"\n",
    "\n",
    "# shape + class balance\n",
    "from collections import Counter\n",
    "cls_counts = Counter()\n",
    "for p in random.sample(paths, min(100, len(paths))):\n",
    "    a = np.load(p)\n",
    "    assert a.shape == (SEQUENCE_LENGTH, FEATURE_DIM), f\"{p}: {a.shape}\"\n",
    "for p in paths:\n",
    "    cls = os.path.basename(os.path.dirname(p))\n",
    "    cls_counts[cls] += 1\n",
    "print(\"per-class augmented counts:\", dict(cls_counts))\n",
    "print(\"total augmented .npy files:\", len(paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "625d8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    FEATURE_COORDS\n",
    "except NameError:\n",
    "    FEATURE_COORDS = 126\n",
    "try:\n",
    "    FEATURE_DIM\n",
    "except NameError:\n",
    "    FEATURE_DIM = 128\n",
    "try:\n",
    "    SEQUENCE_LENGTH\n",
    "except NameError:\n",
    "    SEQUENCE_LENGTH = 24\n",
    "\n",
    "# Augmented directories\n",
    "AUG_INPUT_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")  # where aug .npy live\n",
    "RAW_INPUT_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KEYPOINTS\")           # original extraction dir (for cross-check)\n",
    "AUG_VIZ_DIR   = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\VIZ_AUG\")\n",
    "AUG_VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXPECTED_AUG_SUFFIXES = {\"\", \"_aug1\", \"_aug2\", \"_aug3\", \"_aug4\", \"_aug5\"}  # current code makes 1 original + 5 augs = 6 total per stem\n",
    "\n",
    "def split_coords_flags(arr: np.ndarray):\n",
    "    \"\"\"Return (coords[T,42,3], flags[T,2]) with zero-flags if absent.\"\"\"\n",
    "    T, D = arr.shape\n",
    "    coords = arr[:, :FEATURE_COORDS].reshape(T, 42, 3)\n",
    "    flags  = arr[:, FEATURE_COORDS:FEATURE_COORDS+2] if D >= FEATURE_COORDS+2 else np.zeros((T,2), np.float32)\n",
    "    return coords.astype(np.float32), flags.astype(np.float32)\n",
    "\n",
    "def active_frames_count(flags: np.ndarray):\n",
    "    \"\"\"How many frames w/ any hand present.\"\"\"\n",
    "    return int((flags.sum(axis=1) > 0).sum())\n",
    "\n",
    "def left_right_presence(flags: np.ndarray):\n",
    "    \"\"\"Fraction of frames where left/right flag > 0.5.\"\"\"\n",
    "    T = len(flags)\n",
    "    if T == 0: \n",
    "        return 0.0, 0.0\n",
    "    left_frac  = float((flags[:,0] > 0.5).mean())\n",
    "    right_frac = float((flags[:,1] > 0.5).mean())\n",
    "    return left_frac, right_frac\n",
    "\n",
    "stem_re = re.compile(r\"^(?P<stem>.+?)(?P<suf>(_aug\\d+)?)\\.npy$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4037a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Augmentation Audit ===\n",
      "Per-class augmented counts: {\"Don't Understand\": 168, 'Good Afternoon': 168, 'Good Evening': 176, 'Good Morning': 160, 'Hello': 160}\n",
      "Total augmented .npy files: 832\n",
      "Unique shapes found: {(48, 128): 832}\n",
      "Left_present fraction (avg over sequences):  0.011318\n",
      "Right_present fraction (avg over sequences): 0.545297\n",
      "Active frames (sum): 22181\n",
      "Empty files: 0 | NaN files: 0 | Bad shape/Load issues: 0\n",
      "\n",
      "-- Anomalies --\n",
      "Unexpected suffixes (e.g., legacy _aug0): 104\n",
      "  [Don't Understand] 0: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 1: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 10: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 11: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 12: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 13: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 14: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 15: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 16: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "  [Don't Understand] 17: extras=['_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (showing first 10)\n",
      "Stems with wrong #files (≠6): 104\n",
      "  [Don't Understand] 0: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 1: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 10: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 11: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 12: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 13: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 14: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 15: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 16: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n",
      "  [Don't Understand] 17: found 8 variants -> ['', '_aug1', '_aug2', '_aug3', '_aug4', '_aug5', '_aug6', '_aug7']  (first 10)\n"
     ]
    }
   ],
   "source": [
    "RIGHT_HAND_ONLY = True  # match your augmentation policy\n",
    "\n",
    "if RIGHT_HAND_ONLY:\n",
    "    EXPECTED_AUG_SUFFIXES = {\"\", \"_aug1\", \"_aug2\"}\n",
    "    EXPECTED_PER_STEM = 3\n",
    "else:\n",
    "    EXPECTED_AUG_SUFFIXES = {\"\", \"_aug1\", \"_aug2\", \"_aug3\", \"_aug4\", \"_aug5\"}\n",
    "    EXPECTED_PER_STEM = 6\n",
    "\n",
    "AUG_INPUT_DIR = Path(OUTPUT_DIR)  # audit the augmented directory\n",
    "\n",
    "stem_re = re.compile(r'^(?P<stem>.+?)(?P<suf>_aug\\d+)?\\.npy$')\n",
    "\n",
    "def split_coords_flags_audit(seq):\n",
    "    coords = seq[:, :FEATURE_COORDS].reshape(len(seq), 42, 3)\n",
    "    flags  = seq[:, FEATURE_COORDS:FEATURE_COORDS+2] if seq.shape[1] >= FEATURE_DIM else np.zeros((len(seq),2), np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "def active_frames_count(flags):\n",
    "    # frames where either hand is present\n",
    "    return int((flags.sum(axis=1) > 0.5).sum())\n",
    "\n",
    "def left_right_presence(flags):\n",
    "    left_frac  = float((flags[:,0] > 0.5).mean()) if len(flags) else 0.0\n",
    "    right_frac = float((flags[:,1] > 0.5).mean()) if len(flags) else 0.0\n",
    "    return left_frac, right_frac\n",
    "\n",
    "# override the split used below to avoid relying on augmentation cell's definition\n",
    "def split_coords_flags(arr):\n",
    "    return split_coords_flags_audit(arr)\n",
    "\n",
    "# == Audit augmented files ==\n",
    "per_class_counts = Counter()\n",
    "shape_counts     = Counter()\n",
    "nan_files        = []\n",
    "empty_files      = []\n",
    "bad_shape        = []\n",
    "total_active     = 0\n",
    "left_fracs, right_fracs = [], []\n",
    "\n",
    "# Per class → stem → found suffixes, to detect duplicates/strays (e.g., legacy _aug0)\n",
    "by_class_stem = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for cls_dir in sorted([p for p in AUG_INPUT_DIR.iterdir() if p.is_dir()]):\n",
    "    cls = cls_dir.name\n",
    "    for p in sorted(cls_dir.glob(\"*.npy\")):\n",
    "        m = stem_re.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        stem, suf = m.group(\"stem\"), m.group(\"suf\") or \"\"\n",
    "        by_class_stem[cls][stem].append(suf)\n",
    "\n",
    "        try:\n",
    "            arr = np.load(str(p), allow_pickle=False).astype(np.float32)\n",
    "        except Exception as e:\n",
    "            bad_shape.append((str(p), f\"load_error:{e}\"))\n",
    "            continue\n",
    "\n",
    "        if arr.size == 0:\n",
    "            empty_files.append(str(p))\n",
    "            continue\n",
    "\n",
    "        shape_counts[arr.shape] += 1\n",
    "        if np.isnan(arr).any():\n",
    "            nan_files.append(str(p))\n",
    "\n",
    "        if arr.shape[1] not in (FEATURE_COORDS, FEATURE_DIM):\n",
    "            bad_shape.append((str(p), f\"D={arr.shape[1]}\"))\n",
    "            continue\n",
    "        if arr.shape[0] != SEQUENCE_LENGTH or arr.shape[1] != FEATURE_DIM:\n",
    "            bad_shape.append((str(p), f\"unexpected shape {arr.shape}\"))\n",
    "\n",
    "        coords, flags = split_coords_flags(arr)\n",
    "        total_active += active_frames_count(flags)\n",
    "        lf, rf = left_right_presence(flags)\n",
    "        left_fracs.append(lf)\n",
    "        right_fracs.append(rf)\n",
    "\n",
    "        per_class_counts[cls] += 1\n",
    "\n",
    "# Summaries\n",
    "total_files = sum(per_class_counts.values())\n",
    "avg_left    = float(np.mean(left_fracs)) if left_fracs else 0.0\n",
    "avg_right   = float(np.mean(right_fracs)) if right_fracs else 0.0\n",
    "\n",
    "print(\"=== Augmentation Audit ===\")\n",
    "print(\"Per-class augmented counts:\", dict(per_class_counts))\n",
    "print(\"Total augmented .npy files:\", total_files)\n",
    "print(\"Unique shapes found:\", dict(shape_counts))\n",
    "print(f\"Left_present fraction (avg over sequences):  {avg_left:.6f}\")\n",
    "print(f\"Right_present fraction (avg over sequences): {avg_right:.6f}\")\n",
    "print(\"Active frames (sum):\", total_active)\n",
    "print(\"Empty files:\", len(empty_files), \"| NaN files:\", len(nan_files), \"| Bad shape/Load issues:\", len(bad_shape))\n",
    "\n",
    "# Detect unexpected suffixes / wrong count per stem\n",
    "unexpected = []\n",
    "wrong_cardinality = []\n",
    "for cls, stems in by_class_stem.items():\n",
    "    for stem, sufs in stems.items():\n",
    "        sset = set(sufs)\n",
    "        # Anything not in EXPECTED_AUG_SUFFIXES?\n",
    "        extra = sorted(list(sset - EXPECTED_AUG_SUFFIXES))\n",
    "        if extra:\n",
    "            unexpected.append((cls, stem, extra))\n",
    "        # Expected exactly 6 variants per source stem\n",
    "        if len(sset) != EXPECTED_PER_STEM:\n",
    "            wrong_cardinality.append((cls, stem, sorted(sufs)))\n",
    "\n",
    "print(\"\\n-- Anomalies --\")\n",
    "print(\"Unexpected suffixes (e.g., legacy _aug0):\", len(unexpected))\n",
    "if unexpected:\n",
    "    for cls, stem, extra in unexpected[:10]:\n",
    "        print(f\"  [{cls}] {stem}: extras={extra}  (showing first 10)\")\n",
    "\n",
    "print(\"Stems with wrong #files (≠6):\", len(wrong_cardinality))\n",
    "if wrong_cardinality:\n",
    "    for cls, stem, sufs in wrong_cardinality[:10]:\n",
    "        print(f\"  [{cls}] {stem}: found {len(set(sufs))} variants -> {sufs}  (first 10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b92b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 520 unexpected/duplicate files to: C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented_trash\n"
     ]
    }
   ],
   "source": [
    "# == Optional cleanup: move unexpected files out ==\n",
    "TRASH = AUG_INPUT_DIR.parent / \"KeypointsAugmented_trash\"\n",
    "TRASH.mkdir(exist_ok=True)\n",
    "\n",
    "moved = 0\n",
    "for cls, stems in by_class_stem.items():\n",
    "    cls_dir = AUG_INPUT_DIR / cls\n",
    "    trash_cls = TRASH / cls\n",
    "    trash_cls.mkdir(parents=True, exist_ok=True)\n",
    "    for stem, sufs in stems.items():\n",
    "        sset = set(sufs)\n",
    "        # Move unexpected suffixes\n",
    "        extras = sset - EXPECTED_AUG_SUFFIXES\n",
    "        for suf in extras:\n",
    "            src = cls_dir / f\"{stem}{suf}.npy\"\n",
    "            if src.exists():\n",
    "                dst = trash_cls / src.name\n",
    "                src.rename(dst)\n",
    "                moved += 1\n",
    "        # Also enforce exactly one of each expected; if duplicates, move the duplicates\n",
    "        for suf in EXPECTED_AUG_SUFFIXES:\n",
    "            matches = sorted(cls_dir.glob(f\"{stem}{suf}.npy\"))\n",
    "            if len(matches) > 1:\n",
    "                for dup in matches[1:]:\n",
    "                    dst = trash_cls / dup.name\n",
    "                    dup.rename(dst)\n",
    "                    moved += 1\n",
    "\n",
    "print(f\"Moved {moved} unexpected/duplicate files to: {TRASH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4aaa252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Render summary ===\n",
      "Found:    208\n",
      "Rendered: 208\n",
      "Skipped (already existed): 0\n",
      "Saved to: C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\VIZ_AUG\n"
     ]
    }
   ],
   "source": [
    "# ---- knobs ----\n",
    "AUG_INPUT_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "AUG_VIZ_DIR   = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\VIZ_AUG\")\n",
    "AUG_VIZ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set to True if you want to re-generate videos even when they already exist.\n",
    "OVERWRITE_VIZ = True\n",
    "\n",
    "# Optional: render only specific suffixes; set to None to render everything found.\n",
    "# Examples: ONLY_SUFFIXES = {\"\", \"_aug1\", \"_aug2\", \"_aug3\", \"_aug4\", \"_aug5\"}\n",
    "ONLY_SUFFIXES = {\"_aug1\",\"_aug2\",\"_aug3\",\"_aug4\",\"_aug5\"}\n",
    "\n",
    "# Optional: filter by class names; set to None to include all.\n",
    "ONLY_CLASSES = None  # e.g., {\"Hello\", \"Good Morning\"}\n",
    "\n",
    "# ---- renderer config (same look as before) ----\n",
    "CANVAS_W, CANVAS_H = 1080, 1080\n",
    "MARGIN, POINT_R, THICK = 40, 4, 2\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "INPUT_DURATION_SEC = 8.0\n",
    "SAVE_MP4, PREVIEW = True, False\n",
    "\n",
    "HAND_CONNECTIONS = [\n",
    "    (0,1),(1,2),(2,3),(3,4),\n",
    "    (0,5),(5,6),(6,7),(7,8),\n",
    "    (5,9),(9,10),(10,11),(11,12),\n",
    "    (9,13),(13,14),(14,15),(15,16),\n",
    "    (13,17),(17,18),(18,19),(19,20),\n",
    "    (0,17)\n",
    "]\n",
    "\n",
    "FEATURE_COORDS = 126  # 42*3\n",
    "def split_coords_flags(arr: np.ndarray):\n",
    "    T, D = arr.shape\n",
    "    coords = arr[:, :FEATURE_COORDS].reshape(T, 42, 3).astype(np.float32)\n",
    "    flags  = (arr[:, FEATURE_COORDS:FEATURE_COORDS+2] if D >= FEATURE_COORDS+2 else np.zeros((T,2), np.float32)).astype(np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "def _minmax_xy(coords):\n",
    "    xy = coords[..., :2].reshape(-1, 2)\n",
    "    mask = ~(np.isclose(xy[:,0], 0.0) & np.isclose(xy[:,1], 0.0))\n",
    "    xy = xy[mask]\n",
    "    if xy.size == 0:\n",
    "        return -1.0, 1.0, -1.0, 1.0\n",
    "    return xy[:,0].min(), xy[:,0].max(), xy[:,1].min(), xy[:,1].max()\n",
    "\n",
    "def _project(ptx, pty, x0, y0, scale):\n",
    "    px = int(x0 + ptx * scale)\n",
    "    py = int(y0 + pty * scale)\n",
    "    return px, py\n",
    "\n",
    "def draw_hand(img, pts21, color, x0, y0, scale):\n",
    "    if pts21 is None: return\n",
    "    if np.allclose(pts21, 0.0): return\n",
    "    for a, b in HAND_CONNECTIONS:\n",
    "        ax, ay = _project(pts21[a,0], pts21[a,1], x0, y0, scale)\n",
    "        bx, by = _project(pts21[b,0], pts21[b,1], x0, y0, scale)\n",
    "        cv2.line(img, (ax, ay), (bx, by), color, THICK, cv2.LINE_AA)\n",
    "    for i in range(21):\n",
    "        px, py = _project(pts21[i,0], pts21[i,1], x0, y0, scale)\n",
    "        cv2.circle(img, (px, py), POINT_R, color, -1, cv2.LINE_AA)\n",
    "\n",
    "def make_frame(img, t, T, left_on, right_on):\n",
    "    txt = f\"Frame {t+1}/{T} | Left:{'Y' if left_on else 'N'}  Right:{'Y' if right_on else 'N'}\"\n",
    "    cv2.putText(img, txt, (16, 30), FONT, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "    bar_h = 20\n",
    "    bar_y0 = CANVAS_H - bar_h - 10\n",
    "    bar_y1 = CANVAS_H - 10\n",
    "    cv2.rectangle(img, (MARGIN, bar_y0), (CANVAS_W - MARGIN, bar_y1), (50,50,50), -1)\n",
    "    x0 = MARGIN\n",
    "    x1 = CANVAS_W - MARGIN\n",
    "    xpos = int(x0 + (x1 - x0) * (t / max(1, T-1)))\n",
    "    cv2.line(img, (xpos, bar_y0), (xpos, bar_y1), (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "def render_npy_to_mp4(npy_path: Path, out_mp4_path: Path):\n",
    "    arr = np.load(str(npy_path)).astype(np.float32)\n",
    "    coords, flags = split_coords_flags(arr)  # (T,42,3) and (T,2)\n",
    "    T = coords.shape[0]\n",
    "    L = coords[:, :21, :]\n",
    "    R = coords[:, 21:, :]\n",
    "\n",
    "    xmin, xmax, ymin, ymax = _minmax_xy(coords)\n",
    "    dx = max(1e-6, xmax - xmin)\n",
    "    dy = max(1e-6, ymax - ymin)\n",
    "    scale_x = (CANVAS_W - 2*MARGIN) / dx\n",
    "    scale_y = (CANVAS_H - 2*MARGIN) / dy\n",
    "    scale = 0.9 * min(scale_x, scale_y)\n",
    "    cx, cy = CANVAS_W // 2, CANVAS_H // 2\n",
    "\n",
    "    play_fps = T / max(1e-6, INPUT_DURATION_SEC)\n",
    "\n",
    "    writer = None\n",
    "    if SAVE_MP4:\n",
    "        out_mp4_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        writer = cv2.VideoWriter(str(out_mp4_path), fourcc, play_fps, (CANVAS_W, CANVAS_H))\n",
    "\n",
    "    if PREVIEW:\n",
    "        cv2.namedWindow(\"NPY Visualization (AUG)\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"NPY Visualization (AUG)\", 900, 900)\n",
    "\n",
    "    for t in range(T):\n",
    "        img = np.zeros((CANVAS_H, CANVAS_W, 3), dtype=np.uint8)\n",
    "        left_on  = flags[t,0] > 0.5\n",
    "        right_on = flags[t,1] > 0.5\n",
    "        draw_hand(img, L[t], (255,255,0),  cx, cy, scale)  # Left = cyan\n",
    "        draw_hand(img, R[t], (0,165,255), cx, cy, scale)   # Right = orange\n",
    "        make_frame(img, t, T, left_on, right_on)\n",
    "        cv2.putText(img, \"Left = cyan, Right = orange (normalized coords)\", (16, CANVAS_H-40),\n",
    "                    FONT, 0.6, (200,200,200), 1, cv2.LINE_AA)\n",
    "        if writer is not None: writer.write(img)\n",
    "        if PREVIEW:\n",
    "            key = cv2.waitKey(int(1000 / max(1, int(round(play_fps))))) & 0xFF\n",
    "            if key == 27: break\n",
    "\n",
    "    if writer is not None: writer.release()\n",
    "    if PREVIEW: cv2.destroyAllWindows()\n",
    "\n",
    "# ---- enumerate and render everything ----\n",
    "import re\n",
    "stem_re = re.compile(r\"^(?P<stem>.+?)(?P<suf>(_aug\\d+)?)\\.npy$\")\n",
    "\n",
    "total = 0\n",
    "skipped = 0\n",
    "rendered = 0\n",
    "\n",
    "for cls_dir in sorted([p for p in AUG_INPUT_DIR.iterdir() if p.is_dir()]):\n",
    "    cls = cls_dir.name\n",
    "    if ONLY_CLASSES and cls not in ONLY_CLASSES:\n",
    "        continue\n",
    "    out_dir = AUG_VIZ_DIR / cls\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for npy in sorted(cls_dir.glob(\"*.npy\")):\n",
    "        m = stem_re.match(npy.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        suf = m.group(\"suf\") or \"\"\n",
    "        if ONLY_SUFFIXES is not None and suf not in ONLY_SUFFIXES:\n",
    "            continue\n",
    "\n",
    "        out_mp4 = out_dir / f\"{npy.stem}_viz.mp4\"\n",
    "        total += 1\n",
    "        if out_mp4.exists() and not OVERWRITE_VIZ:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            render_npy_to_mp4(npy, out_mp4)\n",
    "            rendered += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {cls}/{npy.name}: {e}\")\n",
    "\n",
    "print(\"\\n=== Render summary ===\")\n",
    "print(f\"Found:    {total}\")\n",
    "print(f\"Rendered: {rendered}\")\n",
    "print(f\"Skipped (already existed): {skipped}\")\n",
    "print(f\"Saved to: {AUG_VIZ_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d5be3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 *_mirror.npy files to: C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented_trash\n"
     ]
    }
   ],
   "source": [
    "# CLEAN THE MIRRORS AUGMENTATION\n",
    "AUG_INPUT_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "TRASH = AUG_INPUT_DIR.parent / \"KeypointsAugmented_trash\"\n",
    "TRASH.mkdir(exist_ok=True)\n",
    "\n",
    "moved = 0\n",
    "for cls_dir in sorted([p for p in AUG_INPUT_DIR.iterdir() if p.is_dir()]):\n",
    "    trash_cls = TRASH / cls_dir.name\n",
    "    trash_cls.mkdir(parents=True, exist_ok=True)\n",
    "    for p in cls_dir.glob(\"*_mirror.npy\"):\n",
    "        shutil.move(str(p), str(trash_cls / p.name))\n",
    "        moved += 1\n",
    "\n",
    "print(f\"Moved {moved} *_mirror.npy files to: {TRASH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7193295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Compare summary ===\n",
      "Pairs found: 474\n",
      "Rendered:    0\n",
      "Skipped:     474\n",
      "Saved to:    C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\VIZ_COMPARE\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KEYPOINTS\")\n",
    "AUG_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\VIZ_COMPARE\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- filters / knobs ----\n",
    "ONLY_CLASSES   = None  # e.g., {\"Hello\"} to restrict; None = all classes\n",
    "ONLY_SUFFIXES  = {\"\", \"_aug1\",\"_aug2\",\"_aug3\",\"_aug4\",\"_aug5\"}  # which augmented variants to compare\n",
    "OVERWRITE_VIZ  = False\n",
    "INPUT_DURATION_SEC = 4.0  # playback length per clip (slower -> smoother for inspection)\n",
    "\n",
    "# ---- drawing config ----\n",
    "CANVAS_W, CANVAS_H = 720, 720\n",
    "PAD_BETWEEN = 20\n",
    "MARGIN, POINT_R, THICK = 40, 3, 2\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "SAVE_MP4, PREVIEW = True, False\n",
    "\n",
    "# ---- data constants/helpers ----\n",
    "FEATURE_COORDS = 126  # 42*3\n",
    "SEQUENCE_LENGTH = 24  # expected model input length\n",
    "\n",
    "def split_coords_flags(arr: np.ndarray):\n",
    "    T, D = arr.shape\n",
    "    coords = arr[:, :FEATURE_COORDS].reshape(T, 42, 3).astype(np.float32)\n",
    "    flags  = (arr[:, FEATURE_COORDS:FEATURE_COORDS+2] if D >= FEATURE_COORDS+2 else np.zeros((T,2), np.float32)).astype(np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "def resize_sequence(seq: np.ndarray, length: int):\n",
    "    \"\"\"Linear resample to 'length'; binarize flags if present.\"\"\"\n",
    "    seq = np.asarray(seq, dtype=np.float32)\n",
    "    T = len(seq)\n",
    "    if T == 0:\n",
    "        W = seq.shape[1] if seq.ndim == 2 else (FEATURE_COORDS+2)\n",
    "        return np.zeros((length, W), np.float32)\n",
    "    if T == length:\n",
    "        out = seq\n",
    "    else:\n",
    "        idx = np.linspace(0, T-1, length)\n",
    "        lo = np.floor(idx).astype(int)\n",
    "        hi = np.minimum(lo+1, T-1)\n",
    "        w  = (idx - lo)[:,None]\n",
    "        out = (1-w)*seq[lo] + w*seq[hi]\n",
    "    if out.shape[1] >= FEATURE_COORDS + 2:\n",
    "        out[:, FEATURE_COORDS:FEATURE_COORDS+2] = (out[:, FEATURE_COORDS:FEATURE_COORDS+2] >= 0.5).astype(np.float32)\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "HAND_CONNECTIONS = [\n",
    "    (0,1),(1,2),(2,3),(3,4),\n",
    "    (0,5),(5,6),(6,7),(7,8),\n",
    "    (5,9),(9,10),(10,11),(11,12),\n",
    "    (9,13),(13,14),(14,15),(15,16),\n",
    "    (13,17),(17,18),(18,19),(19,20),\n",
    "    (0,17)\n",
    "]\n",
    "\n",
    "def _minmax_xy(coords):\n",
    "    xy = coords[..., :2].reshape(-1, 2)\n",
    "    mask = ~(np.isclose(xy[:,0], 0.0) & np.isclose(xy[:,1], 0.0))\n",
    "    xy = xy[mask]\n",
    "    if xy.size == 0:\n",
    "        return -1.0, 1.0, -1.0, 1.0\n",
    "    return xy[:,0].min(), xy[:,0].max(), xy[:,1].min(), xy[:,1].max()\n",
    "\n",
    "def _project(ptx, pty, x0, y0, scale):\n",
    "    px = int(x0 + ptx * scale)\n",
    "    py = int(y0 + pty * scale)\n",
    "    return px, py\n",
    "\n",
    "def draw_hand(img, pts21, color, x0, y0, scale):\n",
    "    if pts21 is None: return\n",
    "    if np.allclose(pts21, 0.0): return\n",
    "    for a, b in HAND_CONNECTIONS:\n",
    "        ax, ay = _project(pts21[a,0], pts21[a,1], x0, y0, scale)\n",
    "        bx, by = _project(pts21[b,0], pts21[b,1], x0, y0, scale)\n",
    "        cv2.line(img, (ax, ay), (bx, by), color, THICK, cv2.LINE_AA)\n",
    "    for i in range(21):\n",
    "        px, py = _project(pts21[i,0], pts21[i,1], x0, y0, scale)\n",
    "        cv2.circle(img, (px, py), POINT_R, color, -1, cv2.LINE_AA)\n",
    "\n",
    "def make_panel(arr: np.ndarray, title: str):\n",
    "    \"\"\"Returns a function that draws frame t of arr onto a fresh panel image.\"\"\"\n",
    "    coords, flags = split_coords_flags(arr)\n",
    "    T = coords.shape[0]\n",
    "    L = coords[:, :21, :]\n",
    "    R = coords[:, 21:, :]\n",
    "\n",
    "    xmin, xmax, ymin, ymax = _minmax_xy(coords)\n",
    "    dx = max(1e-6, xmax - xmin)\n",
    "    dy = max(1e-6, ymax - ymin)\n",
    "    scale_x = (CANVAS_W - 2*MARGIN) / dx\n",
    "    scale_y = (CANVAS_H - 2*MARGIN) / dy\n",
    "    scale = 0.9 * min(scale_x, scale_y)\n",
    "    cx, cy = CANVAS_W // 2, CANVAS_H // 2\n",
    "\n",
    "    def draw(t: int):\n",
    "        img = np.zeros((CANVAS_H, CANVAS_W, 3), dtype=np.uint8)\n",
    "        left_on  = flags[t,0] > 0.5\n",
    "        right_on = flags[t,1] > 0.5\n",
    "        draw_hand(img, L[t], (255,255,0),  cx, cy, scale)  # Left = cyan\n",
    "        draw_hand(img, R[t], (0,165,255), cx, cy, scale)   # Right = orange\n",
    "        cv2.putText(img, title, (16, 34), FONT, 0.9, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, f\"Frame {t+1}/{T} | L:{'Y' if left_on else 'N'} R:{'Y' if right_on else 'N'}\",\n",
    "                    (16, CANVAS_H-16), FONT, 0.6, (200,200,200), 1, cv2.LINE_AA)\n",
    "        return img\n",
    "    return draw, T\n",
    "\n",
    "stem_re = re.compile(r\"^(?P<stem>.+?)(?P<suf>(_aug\\d+)?)\\.npy$\")\n",
    "\n",
    "def render_side_by_side(raw_path: Path, aug_path: Path, out_path: Path, label_left=\"RAW\", label_right=\"AUG\"):\n",
    "    raw = np.load(str(raw_path)).astype(np.float32)\n",
    "    aug = np.load(str(aug_path)).astype(np.float32)\n",
    "\n",
    "    # For fair visual comparison, resample BOTH to SEQUENCE_LENGTH\n",
    "    raw_r = resize_sequence(raw, SEQUENCE_LENGTH)\n",
    "    aug_r = resize_sequence(aug, SEQUENCE_LENGTH)\n",
    "\n",
    "    left_draw, TL  = make_panel(raw_r, label_left)\n",
    "    right_draw, TR = make_panel(aug_r, label_right)\n",
    "    T = max(TL, TR)  # should both be SEQUENCE_LENGTH\n",
    "\n",
    "    play_fps = T / max(1e-6, INPUT_DURATION_SEC)\n",
    "    H = CANVAS_H\n",
    "    W = CANVAS_W*2 + PAD_BETWEEN\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer = cv2.VideoWriter(str(out_path), fourcc, play_fps, (W, H))\n",
    "\n",
    "    for t in range(T):\n",
    "        left  = left_draw(min(t, TL-1))\n",
    "        right = right_draw(min(t, TR-1))\n",
    "        canvas = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "        canvas[:, :CANVAS_W] = left\n",
    "        canvas[:, CANVAS_W+PAD_BETWEEN:] = right\n",
    "        # vertical divider\n",
    "        cv2.rectangle(canvas, (CANVAS_W, 0), (CANVAS_W+PAD_BETWEEN, H), (25,25,25), -1)\n",
    "        writer.write(canvas)\n",
    "        if PREVIEW:\n",
    "            cv2.imshow(\"Compare RAW vs AUG\", canvas)\n",
    "            if cv2.waitKey(int(1000/max(1,int(round(play_fps))))) & 0xFF == 27:\n",
    "                break\n",
    "    writer.release()\n",
    "    if PREVIEW:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ---- Batch over classes/stems and compare every augmentation ----\n",
    "total_pairs = 0\n",
    "skipped = 0\n",
    "rendered = 0\n",
    "\n",
    "classes = sorted([p.name for p in RAW_DIR.iterdir() if p.is_dir()])\n",
    "if ONLY_CLASSES:\n",
    "    classes = [c for c in classes if c in ONLY_CLASSES]\n",
    "\n",
    "for cls in classes:\n",
    "    raw_cls = RAW_DIR / cls\n",
    "    aug_cls = AUG_DIR / cls\n",
    "    if not aug_cls.exists():\n",
    "        print(f\"[warn] missing augmented class folder: {aug_cls}\")\n",
    "        continue\n",
    "    out_cls = OUT_DIR / cls\n",
    "    out_cls.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Map stems present in RAW\n",
    "    raw_files = sorted(raw_cls.glob(\"*.npy\"))\n",
    "    for raw_p in raw_files:\n",
    "        stem = raw_p.stem  # e.g., \"12\"\n",
    "        # list all aug for this stem\n",
    "        aug_list = []\n",
    "        for aug_p in sorted(aug_cls.glob(f\"{stem}*.npy\")):\n",
    "            m = stem_re.match(aug_p.name)\n",
    "            if not m: \n",
    "                continue\n",
    "            suf = m.group(\"suf\") or \"\"\n",
    "            if ONLY_SUFFIXES is not None and suf not in ONLY_SUFFIXES:\n",
    "                continue\n",
    "            aug_list.append((aug_p, suf))\n",
    "\n",
    "        if not aug_list:\n",
    "            continue\n",
    "\n",
    "        for aug_p, suf in aug_list:\n",
    "            label_right = \"AUG\" + (suf if suf else \" (orig)\")\n",
    "            out_name = f\"{stem}{suf}_COMPARE.mp4\" if suf else f\"{stem}_COMPARE.mp4\"\n",
    "            out_path = out_cls / out_name\n",
    "            total_pairs += 1\n",
    "            if out_path.exists() and not OVERWRITE_VIZ:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            try:\n",
    "                render_side_by_side(raw_p, aug_p, out_path, label_left=\"RAW\", label_right=label_right)\n",
    "                rendered += 1\n",
    "            except Exception as e:\n",
    "                print(f\"[error] {cls}/{raw_p.name} vs {aug_p.name}: {e}\")\n",
    "\n",
    "print(\"\\n=== Compare summary ===\")\n",
    "print(f\"Pairs found: {total_pairs}\")\n",
    "print(f\"Rendered:    {rendered}\")\n",
    "print(f\"Skipped:     {skipped}\")\n",
    "print(f\"Saved to:    {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66ac1c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Augmentation Verification Summary ===\n",
      "Aug dir: C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\n",
      "Classes: [\"Don't Understand\", 'Good Afternoon', 'Good Evening', 'Good Morning', 'Hello', '_webcam_captures']\n",
      "Total .npy files: 312\n",
      "Unique shapes found: {(48, 128)}\n",
      "\n",
      "Per-class file counts:\n",
      "  Don't Understand   63\n",
      "  Good Afternoon     63\n",
      "  Good Evening       66\n",
      "  Good Morning       60\n",
      "  Hello              60\n",
      "  _webcam_captures   0\n",
      "\n",
      "Flag presence fractions (across all frames):\n",
      "  left_present : 0.0114\n",
      "  right_present: 0.5461\n",
      "  pair counts  : {(0, 0): 6646, (1, 0): 152, (0, 1): 8160, (1, 1): 18}\n",
      "\n",
      "Avg detection ratio per sequence (any hand present): 0.556\n",
      "Frozen tail fraction: 0.000 (should be ~0.0)\n",
      "Motion spread pass  : 312/312\n",
      "\n",
      "Issues:\n",
      "  wrong_shape: 0\n",
      "  coord_out_of_range: 3\n",
      "  flag_non_binary: 0\n",
      "  flag_nan: 0\n",
      "\n",
      "Example problems (up to 5 each):\n",
      "\n",
      "coord_out_of_range:\n",
      " - (\"C:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO\\\\MODIFIABLE - PD\\\\KeypointsAugmented\\\\Don't Understand\\\\12.npy\", 5.000845432281494)\n",
      " - (\"C:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO\\\\MODIFIABLE - PD\\\\KeypointsAugmented\\\\Don't Understand\\\\9.npy\", 5.007062911987305)\n",
      " - ('C:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO\\\\MODIFIABLE - PD\\\\KeypointsAugmented\\\\Hello\\\\12.npy', 5.00234317779541)\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "AUG_DIR         = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "SEQUENCE_LENGTH = 48\n",
    "APPEND_FLAGS    = True\n",
    "FEATURE_COORDS  = 42 * 3\n",
    "FEATURE_DIM     = FEATURE_COORDS + (2 if APPEND_FLAGS else 0)  # 128\n",
    "CLIP_LIMIT      = 5.0\n",
    "EPS_MOTION      = 5e-4\n",
    "\n",
    "# ---- helpers (mirror extraction logic) ----\n",
    "def split_coords_flags(arr: np.ndarray):\n",
    "    T, D = arr.shape\n",
    "    coords = arr[:, :FEATURE_COORDS].reshape(T, 42, 3)\n",
    "    if APPEND_FLAGS and D >= FEATURE_COORDS + 2:\n",
    "        flags = arr[:, FEATURE_COORDS:FEATURE_COORDS+2]\n",
    "    else:\n",
    "        flags = np.zeros((T,2), np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "def tail_is_frozen(coords: np.ndarray, k=6, eps=EPS_MOTION) -> bool:\n",
    "    k = min(k, coords.shape[0]-1) if coords.shape[0] > 1 else 1\n",
    "    tail = coords[-(k+1):]\n",
    "    if tail.shape[0] < 2: \n",
    "        return True\n",
    "    diffs = np.abs(np.diff(tail, axis=0)).mean()\n",
    "    return bool(diffs < eps)\n",
    "\n",
    "def motion_spread_pass(coords: np.ndarray, eps=EPS_MOTION, min_ratio=0.25) -> bool:\n",
    "    \"\"\"Pass if at least min_ratio of frame-to-frame motion exceeds eps.\"\"\"\n",
    "    if coords.shape[0] < 2: \n",
    "        return False\n",
    "    v = np.linalg.norm(np.diff(coords, axis=0), axis=(1,2))\n",
    "    return (v > eps).mean() >= min_ratio\n",
    "\n",
    "# ---- scan & validate ----\n",
    "per_class_counts = Counter()\n",
    "issues = {\n",
    "    \"wrong_shape\": [],\n",
    "    \"coord_out_of_range\": [],\n",
    "    \"flag_non_binary\": [],\n",
    "    \"flag_nan\": [],\n",
    "}\n",
    "pair_counts = Counter()   # (L_flag, R_flag)\n",
    "det_ratio_accum = []\n",
    "frozen_tail_flags = []\n",
    "motion_spread_flags = []\n",
    "\n",
    "classes = [d for d in sorted(os.listdir(AUG_DIR)) if (AUG_DIR / d).is_dir()]\n",
    "total_files = 0\n",
    "unique_shapes = set()\n",
    "\n",
    "for cls in classes:\n",
    "    cdir = AUG_DIR / cls\n",
    "    files = sorted([p for p in cdir.glob(\"*.npy\")])\n",
    "    per_class_counts[cls] += len(files)\n",
    "    for f in files:\n",
    "        total_files += 1\n",
    "        arr = np.load(f, allow_pickle=False)\n",
    "        unique_shapes.add(arr.shape)\n",
    "\n",
    "        # 1) shape check\n",
    "        if arr.shape != (SEQUENCE_LENGTH, FEATURE_DIM):\n",
    "            issues[\"wrong_shape\"].append((str(f), arr.shape))\n",
    "            # skip deeper checks for wrong-shaped files\n",
    "            continue\n",
    "\n",
    "        coords, flags = split_coords_flags(arr)\n",
    "\n",
    "        # 2) coord range check\n",
    "        max_abs = np.abs(coords).max(initial=0.0)\n",
    "        if not np.isfinite(max_abs) or (max_abs > (CLIP_LIMIT + 1e-5)):\n",
    "            issues[\"coord_out_of_range\"].append((str(f), float(max_abs)))\n",
    "\n",
    "        # 3) flags sanity: binary & non-NaN\n",
    "        if np.isnan(flags).any():\n",
    "            issues[\"flag_nan\"].append(str(f))\n",
    "        # allow small numeric noise, but force round for check\n",
    "        fb = np.round(flags).astype(np.int32)\n",
    "        if not np.array_equal(flags, fb.astype(flags.dtype)):\n",
    "            # tolerate tiny floating error by thresholding at 0.5\n",
    "            fx = (flags >= 0.5).astype(np.float32)\n",
    "            if not np.array_equal(fx, flags):\n",
    "                issues[\"flag_non_binary\"].append(str(f))\n",
    "            flags = fx  # keep binarized version for downstream statistics\n",
    "\n",
    "        # 4) detection ratio & pair stats\n",
    "        det = (flags.sum(axis=1) > 0).astype(np.int32)\n",
    "        det_ratio_accum.append(det.mean())\n",
    "\n",
    "        for l, r in flags:\n",
    "            pair_counts[(int(l), int(r))] += 1\n",
    "\n",
    "        # 5) tail frozen & motion spread quick checks\n",
    "        frozen_tail_flags.append(tail_is_frozen(coords, k=6, eps=EPS_MOTION))\n",
    "        motion_spread_flags.append(motion_spread_pass(coords, eps=EPS_MOTION, min_ratio=0.25))\n",
    "\n",
    "# ---- report ----\n",
    "print(\"\\n=== Augmentation Verification Summary ===\")\n",
    "print(f\"Aug dir: {AUG_DIR}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Total .npy files: {total_files}\")\n",
    "print(f\"Unique shapes found: {unique_shapes}\")\n",
    "\n",
    "print(\"\\nPer-class file counts:\")\n",
    "for k,v in per_class_counts.items():\n",
    "    print(f\"  {k:<18} {v}\")\n",
    "\n",
    "# pair stats\n",
    "total_pairs = sum(pair_counts.values()) or 1\n",
    "lp = (pair_counts[(1,0)] + pair_counts[(1,1)]) / total_pairs\n",
    "rp = (pair_counts[(0,1)] + pair_counts[(1,1)]) / total_pairs\n",
    "print(\"\\nFlag presence fractions (across all frames):\")\n",
    "print(f\"  left_present : {lp:.4f}\")\n",
    "print(f\"  right_present: {rp:.4f}\")\n",
    "print(f\"  pair counts  : {dict(pair_counts)}\")\n",
    "\n",
    "# detection & motion stats\n",
    "if det_ratio_accum:\n",
    "    det_avg = float(np.mean(det_ratio_accum))\n",
    "    print(f\"\\nAvg detection ratio per sequence (any hand present): {det_avg:.3f}\")\n",
    "else:\n",
    "    print(\"\\nAvg detection ratio per sequence: n/a\")\n",
    "\n",
    "frozen_rate = np.mean(frozen_tail_flags) if frozen_tail_flags else float('nan')\n",
    "spread_rate = np.mean(motion_spread_flags) if motion_spread_flags else float('nan')\n",
    "print(f\"Frozen tail fraction: {frozen_rate:.3f} (should be ~0.0)\")\n",
    "print(f\"Motion spread pass  : {int(np.sum(motion_spread_flags))}/{len(motion_spread_flags)}\")\n",
    "\n",
    "# issues\n",
    "any_issues = any(len(v) for v in issues.values())\n",
    "print(\"\\nIssues:\")\n",
    "for k, lst in issues.items():\n",
    "    print(f\"  {k}: {len(lst)}\")\n",
    "if any_issues:\n",
    "    print(\"\\nExample problems (up to 5 each):\")\n",
    "    for k, lst in issues.items():\n",
    "        if not lst: \n",
    "            continue\n",
    "        print(f\"\\n{k}:\")\n",
    "        for item in lst[:5]:\n",
    "            print(\" -\", item)\n",
    "else:\n",
    "    print(\"  None\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dde038ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clamped & saved 3 files.\n"
     ]
    }
   ],
   "source": [
    "# TO FIX IF THERE IS COORD OUT OF RANGE, AFTER RUNNING THIS RE-RUN PREVIOUS CELL\n",
    "AUG_DIR = Path(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\MODIFIABLE - PD\\KeypointsAugmented\")\n",
    "FEATURE_COORDS = 42*3\n",
    "CLIP_LIMIT = 5.0\n",
    "\n",
    "def split_coords_flags(arr):\n",
    "    T, D = arr.shape\n",
    "    coords = arr[:, :FEATURE_COORDS].reshape(T, 42, 3)\n",
    "    flags  = arr[:, FEATURE_COORDS:] if D > FEATURE_COORDS else np.zeros((T,2), np.float32)\n",
    "    return coords, flags\n",
    "\n",
    "fixed = 0\n",
    "for f in AUG_DIR.rglob(\"*.npy\"):\n",
    "    arr = np.load(f, allow_pickle=False)\n",
    "    coords, flags = split_coords_flags(arr)\n",
    "    max_abs = np.abs(coords).max()\n",
    "    if not np.isfinite(max_abs): \n",
    "        continue\n",
    "    if max_abs > CLIP_LIMIT + 1e-6:\n",
    "        coords = np.clip(coords, -CLIP_LIMIT, CLIP_LIMIT).astype(np.float32)\n",
    "        arr = np.concatenate([coords.reshape(len(coords), FEATURE_COORDS), flags.astype(np.float32)], axis=1).astype(np.float32)\n",
    "        np.save(f, arr)\n",
    "        fixed += 1\n",
    "\n",
    "print(f\"Clamped & saved {fixed} files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaEnviTensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
